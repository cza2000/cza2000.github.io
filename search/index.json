[{"content":"在之前的几个 projects 中，我们已经构建起了基于 multi-raft 的分布式KV数据库。在 project 4 中，我们将构建一个事务系统以应对多个 clinet 的并发请求并保证快照隔离（snapshot isolation）。\n我们将基于Percolator的两阶段提交协议来构建我们的事务模型。\nPart A：MVCC 在part A中我们需要实现MVCC即多版本并发控制（multi-version concurrency control）。tinykv的底层存储Badger为我们提供了3个column family：CfDefault、CfLock、CfWrite，对应了论文中提到的3个列：data、lock、write。\n CfDefault：用于暂时存储对应key的value值，将由MVCC机制来决定之后该值是否被commit或者被delete（即回滚） CfLock：用于存储锁，如果某key存在对应key的lock，说明它正在被某个事务修改。 CfWrite：用来存储key的每个版本value值的提交时间(commit version) WriteKind：Lock和Write都有一个write kind属性来记录本次对key进行了什么样的修改。有三种，分别是Put、Delete和Rollback。  我们依据论文，使用Badger提供的读写api来完成 transaction.go 中的MvccTxn和它的方法。\n// MvccTxn groups together writes as part of a single transaction. It also provides an abstraction over low-level // storage, lowering the concepts of timestamps, writes, and locks into plain keys and values. type MvccTxn struct { StartTS uint64 Reader storage.StorageReader writes []storage.Modify } MvccTxn struct中需要包含事务开始的timestamp StartTS，底层存储的Reader和用来将一系列写操作原子化的writes数组。\n这里需要注意一下CfDefault、CfLock、CfWrite这三个column family的key/value编码方式。\n    key value     CfDefault (key, StartTS) value   CfLock key lock   CfWrite (key, commitTS) write    写、删除只需构建一个storage.Modify结构添加到MvccTxn的writes中即可。读操作的实现稍微复杂。\n  GetValue\n GetValue finds the value for key, valid at the start timestamp of this transaction. I.e., the most recent value committed before the start of this transaction.\n 根据注释，这个方法要求我们读出在事务开始之前最晚写入的值。在论文中提到：一个值只有被commit后才对其他事务可见，表现为一个write记录。很容易想到应该去读 CfWrite 这个CF。又根据方法EncodeKey的编码规则，key按照userkey升序，userkey相同时按照timestamp降序，我们可以适当编码key并调用seek，使迭代器指向 CfWrite 这个CF中事务开始之前最晚写入的值。此后还需要注意两点：得到的write的key可能不等于userkey，需要特判；判断write的类型可能为WriteKindDelete，这表示这个userkey已经被删除，应该返回nil。最后根据write中的StartTS从CfDefault中读取value。\n  CurrentWrite\n我们需要搜索：对于key，startTS和事务的开始时间相同的write。\n我们可以直接遍历 CfWrite 这个CF从中找到符合条件的write。从中找到由于userkey相同时key的编码按timestamp降序，我们在调用EncodeKey时将timestamp设置为^uint64(0)，之后即可遍历对于userkey的所有write。\n  MostRecentWrite\n我们需要找到对于给定的userkey最迟的write。使用和CurrentWrite中相似的编码方式，在 CfWrite 中查找即可。\n  Part B\u0026amp;C: transactional API 在Part B中我们需要实现KvGet, KvPrewrite, 和KvCommit三个request handler。\nKvGet KvGet 根据事务的StartTS读出key对应的value，应当判断该key在读事务的StartTS处是否被其他事务上锁，即查找key是否存在锁且锁的startTS是否早于事务的startTS。\ntxn := mvcc.NewMvccTxn(reader, req.GetVersion()) lock, err := txn.GetLock(key) if err != nil { return nil, err } // lock\u0026#39;s ts \u0026lt;= txn\u0026#39; ts means the key are locked before txn start and not commited yet \tif lock != nil \u0026amp;\u0026amp; lock.Ts \u0026lt;= txn.StartTS { resp.Error = \u0026amp;kvrpcpb.KeyError{ Locked: \u0026amp;kvrpcpb.LockInfo{ PrimaryLock: lock.Primary, LockVersion: lock.Ts, Key: key, LockTtl: lock.Ttl, }, } return resp, nil } 若key未被上锁，调用 GetValue 读取。\nKvPrewrite KvPrewrite 先检查每一个key是否可以被写入，并对每一个key上一个指向primary key的锁 。 KvCommit 检查所有锁是否仍有效并commit所有key。它们共同构成了 Percolator 事务的两阶段提交。\nKvPrewrite 需要将value写入每个key的data列，并对该key上锁以防止其他事务的写冲突（即分别写入 CfDefault 和 CfLock）。在此之前需要判断没有其他事务也对相同的key上锁或写入。我们应循环检查每一个key是否可以被合法的prewirte。\n 首先应该判断是否有其他事务在本事务开始之后提交了相同key的commit，若有则需要记录该冲突并检查下一个key。这里可以调用 MostRecentWrite 来找到对于key最近的commit记录，再判断是否冲突（冲突即commitTs \u0026gt; 事务的version）。 检查key是否在事务开始之前被加锁。 在本地事务中写入value、lock。  循环结束后应判断是否出现冲突，若出现冲突则直接abort本次事务，防止写-写冲突。若没有冲突，调用storage.Write提交对于CfDefaule和CfLock的写入。\nKvCommit 需要先检查所有的锁的状态。\n 若锁不存在，表明可能原事务rollback或锁过期，则本次commit失败。 若锁存在，但startTS不等于本次commit请求的startVersion，表明该锁不属于我们期望commit的原事务，而是被其他事务加的锁，本次commit失败。此时需要在resp.Error中的retryable字段处记录，让client重试。  若锁状态符合要求，删除锁并写入write以提交commit。这两个操作需要加锁latch来保证原子性。\nKvScan KvScan 一次读取 multiple key/value pairs。\nbadger自带的迭代器只支持在指定的CF中按key顺序迭代，而事务要求我们只能读取在startTS之前提交的value，这需要我们对于每一个key先找到符合条件的write记录，再去CfDefault列中获取对应的value。\n下面我们实现一个支持事务的迭代器。\n// NewScanner creates a new scanner ready to read from the snapshot in txn. func NewScanner(startKey []byte, txn *MvccTxn) *Scanner { // Your Code Here (4C). \tscan := Scanner{ txn: txn, iter: txn.Reader.IterCF(engine_util.CfWrite), lastKey: []byte{}, } scan.iter.Seek(EncodeKey(startKey, txn.StartTS)) return \u0026amp;scan } 它包含一个CfWrite列的迭代器。以及一个 lastKey 字段，它记录找到的上一个符合条件的write所对应的Key。\n最核心的是Scanner.Next函数，它返回下一个符合事务条件的key/value。\n首先移动迭代器，使其指向第一个满足 key != lastKey 的write记录。\nvar currentUserKey []byte for scan.iter.Valid() { currentUserKey = DecodeUserKey(scan.iter.Item().KeyCopy(nil)) if !bytes.Equal(currentUserKey, scan.lastKey) { break } scan.iter.Next() } 循环使用seek寻找 EncodeKey(currentUserKey, scan.txn.StartTS) 或之后的第一个 key。需要注意在 currentUserKey 处可能没有在 txn.StartTS 之前的commit，这会使迭代器指向下一个userKey最早的commit。\n// now we find a key that userKey != lastKey, seek commitTs \u0026lt; startTs \tfor currentCommitTs \u0026gt; scan.txn.StartTS { scan.iter.Seek(EncodeKey(currentUserKey, scan.txn.StartTS)) if !scan.iter.Valid() { return nil, nil, nil } currentUserKey = DecodeUserKey(scan.iter.Item().KeyCopy(nil)) currentCommitTs = decodeTimestamp(scan.iter.Item().KeyCopy(nil)) } 这样我们便找到了下一个commitTS符合要求的userkey，只需去 CfDefault 中读取value即可。\n此后我们可以简单的实现 KvScan ，只需根据startKey和limit建立事务迭代器实例，并循环调用Next获取key / value对。\nKvCheckTxnStatus KvCheckTxnStatus 报告事务的状态，并回滚过期的锁。\n需要注意 CheckTxnStatusResponse 中给出的注释。\n// Three kinds of txn status:  // locked: lock_ttl \u0026gt; 0  // committed: commit_version \u0026gt; 0  // rolled back: lock_ttl == 0 \u0026amp;\u0026amp; commit_version == 0 为了确认事务是否以及被回滚或提交，应当先查找 (primary key, lockTS) 对应的write记录，这里可以使用 CurrentWrite 函数，这要求我们使用req.lockTS来初始化本次事务。若存在write记录，设置 resp.Action = kvrpcpb.Action_NoAction。还需要判断write的类型，若类型为 WriteKindRollback 则需要在resp中的 CommitVersion 记录write 的commitTS。\n之后需要确认锁的状态。若锁不存在，则需要回滚primary key，并记录 resp.Action = kvrpcpb.Action_LockNotExistRollback。若锁存在，判断ttl是否过期。若过期则删除锁和value并回滚，并记录 resp.Action = kvrpcpb.Action_TTLExpireRollback。这里判断ttl需要使用 physical time。\n若锁仍有效，在 resp.LockTtl 字段中记录剩余ttl并返回。\nKvBatchRollback KvBatchRollback 批量回滚事务。检查每个key是否仍被原事务上锁，如果是则删除锁和value，回滚该事务。\n循环检查每一个key\n  检查该key是否已经被回滚或提交。若已被回滚则忽略该key，若已被commit则在resp.Error.Abort 中记录错误信息并直接返回。可以调用 MostRecentWrite 来获取最近提交的write。\n  检查该key是否存在锁。\n 若不存在，直接回滚该key。 若存在。  锁不属于原事务，视为出错，回滚该事务。 锁仍属于原事务，执行所有回滚步骤，删除锁、value，再回滚。      若循环过程中发生出错则不将txn中的writes写入storage，即一个key出错视为全部出错。\nKvResolveLock KvResolveLock 将查找属于具有给定开始时间戳的事务的所有锁，要么将他们全部回滚，要么全部commit。\n首先要根据startVersion找到所有的lock，我们遍历CfLock找到所有满足 lock.Ts == req.StartVersion 的lock。之后根据 req.CommitVersion 是否为零决定回滚或是commit，相应操作可以直接调用 KvBatchRollback 或者 KvCommit 。\n","date":"2022-02-05T21:26:29+08:00","permalink":"https://ziannchen.work/2022/tinykv-project4-transaction/","title":"TinyKV Project4: Transaction"},{"content":"在本项目中我们需要实现基于多个raft集群的KV服务器，其中的每一个raft集群只负责固定范围内的关键字，从而解决raft算法为了追求一致性而影响了并发性的问题。\n为了支持这样的设计，我们需要完成三个部分的内容：\n  为我们的raft算法添加集群成员变更以及领导权变更的功能。\n  在raftstore中实现配置变更以及region分裂。\n  实现一个调度算法用于合理地变化配置，获得更好的服务器调度性能。\n  Part A：实现集群成员变更以及领导权变更 领导权变更 在这个部分我们需要引入两个新的消息类型。MsgTransferLeader使得目前的leader检查其继任者的状态，MsgTimeoutNow驱动继任者无视其ElectionTimeOut立即发动选举。在leader帮助其更新日志并且其他follower的时钟都为随机设定的条件下，它有相当高的几率成为新的leader，而这也正是我们所期望的。\n在handleTransforLeader函数中定义了leader面对领导权变更时的行为。对于MsgTransferLeader，它的from成员应当是上层设定的transferee。因此应当排除三种错误情况：\n  和一般的local message一样，from成员等于自身id的情况。\n  leader的transferee已经设定并且等于from的情况(说明有已经在运行的领导权变更，无需重复执行)。\n  将要确定的transferee不在leader记录的peer中的情况。\n  在排除以上三种情况之后，我们需要检查transferee的log是否是最新的，这样才能不与正常的选举规则冲突。若不是，则应调用sendAppend函数向它发送缺少的entry。在transferee的记录已经最新的情况下，leader应当调用sendTimeoutNow函数向其发送MsgTimeoutNow消息使其立刻发动新的选举。\n收到MsgTransferLeader消息时，follower将其转发给leader。follower收到MsgTimeoutNow之后调用step函数，参数为MsgHup类型的消息。follower接着就会立即将计时器置零并发动选举。\n配置变更 与论文中相同的是，为了支持配置变更，我们需要一个特殊的entry来记录配置的参数。因此需要在raft/rawnode.go中加入ProposeConfChange函数，它将entry的类型设置为EntryConfChange并将数据设置为ConfChange的相应字节，最后向raft层发送一个带有这样的entry，并且类型为MsgPropose的消息。\nMsgPropose类型的消息只会被leader受理，它将其加入自己的log之中并且尝试向follwer发送并提交消息中的entry，这与我们在项目2中所做的并没有什么区别，只需要在raft.go中的handlePropose函数内加入设置PendingConfIndex的代码，将它设置为第一个配置变更的entry的index并暂时不受理其他的配置变更。\n对于Part A，我们只需要在rawnode.go中加入ApplyConfChange函数，用于处理一个节点的参数变化。为了实现这个功能，我们在raft层中加入了addNode与removeNode函数，它们都具有相当直观的实现。\nAddNode函数在raft的peers中添加相应的peer，并且初始化它的Progress，最后将raft的PendingConfIndex清空，使其能够处理下一个配置变更的消息。\nremoveNode函数则较为复杂一些：\n(1) 首先检查需要删除的raft是否在当前配置之中，若不在则直接返回，若在则转(2)。\n(2) 检查自身是否为需要删除的peer，若是则清空自己的peers并且返回。若不是则转(3)。\n(3) 删除相应的peer，并检查自己的peer数量。若为1，则它需要成为这个集群的leader。\n(4) 删除peer后，原先不满足commit条件的entry有可能已经满足，调用maybeAdvanceCommit函数进行提交。\n(5) 最后清空PendingConfIndex。\nPart B: 在raftstore中实现配置变更以及region分裂 Propose transfer leader TransferLeader直接被发送给集群中的leader，不需要被复制到多个peer上，因此不需要记录在proposal中，直接调用RawNode.TransferLeader。\nImplement conf change in raftstore 在raft层需要在PendingConfIndex字段中记录类型为EntryType_EntryConfChange的日志项的index，当配置变更被apply后落实到raft层后清空这个字段。在propose的时候，如果这个字段不为None则直接返回，表示还有一次配置变更没有完成。之后调用RawNode.ProposeConfChange。\nHandleRaftReady中由于存在配置变更的情况，在应用了Ready中的快照后region可能发生改变，。因此在SaveReadyState之后需要修改d.ctx.storeMeta。\n处理CommittedEntries的部分代码也需要重构以特殊处理EntryType_EntryConfChange类型的日志项。\nif len(rd.CommittedEntries) \u0026gt; 0 { for _, e := range rd.CommittedEntries { kvwb := new(engine_util.WriteBatch) switch e.EntryType { case eraftpb.EntryType_EntryNormal: d.processNormalEntry(e, kvwb) case eraftpb.EntryType_EntryConfChange: d.processConfChangeEntry(e, kvwb) } if d.stopped { return } else { d.peerStorage.applyState.AppliedIndex = e.Index log.Infof(\u0026#34;%s successfully apply entry from raft peer %d [index: %d]\u0026#34;, d.Tag, d.PeerId(), e.Index) kvwb.SetMeta(meta.ApplyStateKey(d.regionId), d.peerStorage.applyState) } kvwb.WriteToDB(d.peerStorage.Engines.Kv) } } 在添加或是删除node时，都需要先判断目标node是否已存在当前的region的peers中。配置变更之后，还需要增加region.RegionEpoch.ConfVer，修改peerCache。如果删除了自己，需要调用destroyPeer并直接返回，此后的日志项也不需要再处理。 新建的peer无需我们关心，他会在收到leader的心跳后被初始化，之后接收快照来达到接近region内其他peer的状态。\nImplement split region in raftstore 为了支持multi-raft，TinyKV对于较大的region进行分裂，有助于均衡集群内各个机器的负载。\n在propose的时候需要检查SplitKey是否合法，不合法则直接返回。\nregion分裂需要将region中的每一个peer都分裂为两个。split消息会被复制到region中的所有peer上，并由每一个peer在apply时将自己分裂，这样就完成了分裂，而且他们共用同一个store。\nSplit属于AdminRequest，在处理的时候需要先依次检查RegionId、RegionEpoch、SplitKey是否都合法，若检查通过则开始分裂。\n首先，原先的region从splitkey处分裂为两个，key range分别为[startKey, splitkey)和[splitkey, endkey)。因此需要新建一个region，其中RegionEpoch中的ConfVer和Version都设为1，在原先的region中增加RegionEpoch.Version。\n然后需要修改d.ctx.storeMeta，删除旧的region信息，记录两个新的region信息。调用WriteRegionState持久化两个新的region，state要设置为PeerState_Normal。\n最后，调用createPeer新建一个peer，并在route中注册，向其发生一个MsgTypeStart信息。不要忘了处理proposal。\nPart C：实现调度器 调度器根据集群的负载选择每个region中每个副本的最佳位置，因此需要获取整个集群的所有关键信息，并定期检查这些信息以做出调度。\nCollect region heartbeat 调度器要求每个region中的leader定期向它发送心跳信息。\n我们需要实现RaftCluster.processRegionHeartbeat函数，更新本地保存的region信息。\n在此之前我们先实现一个checkRegionEpoch来判断新的region信息是否合法且是否过期。\nfunc checkRegionEpoch(region *core.RegionInfo, origin *core.RegionInfo) error { if region.GetRegionEpoch() == nil || origin.GetRegionEpoch() == nil { return errors.Errorf(\u0026#34;region is nil\u0026#34;) } if util.IsEpochStale(region.GetRegionEpoch(), origin.GetRegionEpoch()) { return ErrRegionIsStale(region.GetMeta(), origin.GetMeta()) } return nil } 我们先需要根据心跳中的regionInfo的regionId先获取本地保存的region信息。若本地存在且新的region过期，直接返回错误。若不存在，遍历本地所有包含了新region的key range的region信息，检查新的region对于它是否过期，若存在过期则直接返回错误。\n若新的region未过期，则更新本地存储，包括了region tree和store status。\nImplement region balance scheduler 这一部分需要实现balanceRegionScheduler.Schedule函数，它负责进行region的调度，返回一个MovePeerOperator，将某个peer在store之间移动。\n首先寻找合适的可移动的region，在此之前需要寻找所有合适的store，即：正在运行并且 downTime 小于 store的最大downTime 的所有store。如果suitableStores数量小等于1，不能进行MovePeer，则停止本次调度返回nil。之后将所有suitableStores按照拥有的region大小从大到小排序。\n接着我们遍历suitableStores，在每个store上按照PendingRegionsWithLock -\u0026gt; FollowerWithLock -\u0026gt; LeadersWIthLock的优先级选出第一个满足条件的region，这便是我们想要移动的region。如果没有找到合适的region，或是该region的副本数小于MaxReplicas，则停止本次调度返回nil。\n最后我们寻找接收peer的目标store，即拥有的region大小最小且不在suitableStores中的store。如果sourceStore.GetRegionSize()-targetStore.GetRegionSize() \u0026lt;= region.GetApproximateSize()*2，则本次调度不能进行。之后调用AllocPeer在targetStore上新建一个peer，调用CreateMovePeerOperator生成operator返回。\n","date":"2022-02-05T21:19:15+08:00","permalink":"https://ziannchen.work/2022/tinykv-project3-multiraftkv/","title":"TinyKV Project3: MultiRaftKV"},{"content":"在本项目中我们需要实现一个基于 raft 分布式共识算法的高可用kv存储服务器，它既需要我们实现Raft算法也需要我们知道如何实际使用它。\n我们通过3个步骤来达成这一目标：\n 实现基本的Raft算法。 在Raft之上构建一个可容错的KV服务。 添加对于raft日志垃圾回收以及快照的支持。  Part A：实现基本的Raft算法 raft层中没有物理时钟，而是使用一个逻辑时钟。上层应用通过调用RawNode.Tick()来推动逻辑时钟，进而推动election \\ heartbeat timeout的发生，从而推动了raft状态机。\n 在Raft.tick函数中，根据Raft.State推动election timeout或是 heartbeat timeout。这是通过控制electionElapsed和heartbeatElapsed进行自增操作实现的，当electionElapsed \u0026gt;= randomizeElectionTimeout时触发一次选举，当heartbeatElapsed \u0026gt;= heartbeatTimeout时触发一次心跳。触发之后对应地要清零Elapsed。  raft中不同peer之间、raft层与上层应用之间收发消息都是异步的。在raft层中只需将希望发出的消息存入Raft.msg中，上层应用会在调用HandleRaftReady处理消息并转发到目标处。上层应用同时为每个收到的消息调用Raft.Step让raft层处理消息。\n raft中定义的不同Message有不同的MsgType。根据论文，不同的MsgType只能拥有特定的raft状态的peer才能处理，如下表所示。每个消息先在Raft.Step函数中根据此时raft状态的的不同被路由到对应的不同状态的step函数中处理，再根据消息类型的不同由对应的handlexxx函数处理。     Msgtype State     pb.MessageType_MsgHup L、C、F   pb.MessageType_MsgBeat L   pb.MessageType_MsgPropose L   pb.MessageType_MsgAppend L、C、F   pb.MessageType_MsgAppendResponse L   pb.MessageType_MsgRequestVote L、C、F   pb.MessageType_MsgRequestVoteResponse C   pb.MessageType_MsgSnapshot L、C、F   pb.MessageType_MsgHeartbeat L、C、F   pb.MessageType_MsgHeartbeatResponse L   pb.MessageType_MsgTransferLeader L、C、F   pb.MessageType_MsgTimeoutNow C、F    newRaft函数，根据传入的一个Config参数创建一个raft peer实例。\n  Raft.RaftLog需要调用newLog函数，需要注意Raft中的entries和Storage中entries数组下标、日志项index、几个特殊的index之间的关系。\n  Raft.Prs记录了同一个region内各个peer的日志同步情况。 还有一个隐含的作用是记录了同一个region内各个peer的id，也让我们知道了peer的数量，这在有时候很有用。\n  Leader election 首先要实现becomexxx函数。根据论文可以很容易实现\n becomeFollower：更新State、Vote、Term、Lead，将electionElapsed清零。 becomeCandidate：更新State，将Vote设为自己的id，清空votes、Lead、electionElapsed，设置votes[r.id] = true，增加Term。 becomeLeader：更新State、heartbeatElapsed，将Lead设为自己的id，更新Prs，自增一条空日志并广播（每个leader只会commit本term内的日志，如此可以保证集群的可用性）。需要注意的是如果当前Region中只有自己，则直接commit该条日志。  发起选举的过程是在startElection中实现。调用becomeCandidate，并向其他peer广播RequestVote消息。在消息中需要附加自身的最后一条日志的Index和term。需要注意的是，若region中只有自己一个节点，则直接成为leader。\n处理candidate发来的RequestVote消息是在handleRequestVote函数中实现。\n 如果消息中的Term比自身的Term小，拒绝投票。 如果r.Vote != None \u0026amp;\u0026amp; r.Vote != m.From，这意味着在本次任期中已经为另一个peer投过票，拒绝投票。 判断消息发送者的日志是否比自己更up-to-date。若不是，拒绝投票。 至此，同意投票，更新自身Vote字段。  处理其他peer回复的RequestVoteResponse是在handleRequestVoteResponse函数中实现。\n 如果消息的Term比自己的Term小，拒绝处理该消息。这意味着这个消息是过时的。 如果同意投票，更新r.votes。如果同意投票的数量过半，自己成为leader；如果拒绝投票的数量过半，自己退化为follower。  成为leader后要定期广播心跳，通过调用boardcastHeartbeat来进行广播，在消息中附加自己的Term。\nLog replication leader在Prs中记录同一region中各个peer的日志同步情况，在某个peer日志落后时要进行日志复制，在上层应用向raft层Propose日志后也要进行广播日志复制。\n发送日志复制的操作在sendAppend中处理。r.Prs[to].Next代表需要向to复制的第一条日志的index，如果这条日志已经被compact了，则转为发送snapshot。发送日志时还需要附带前一条日志的index和term以及自己的commit。\n接收到leader的日志复制消息后，相应的处理在handleAppendEntries中。\n 若消息的term比自身小，这表示原leader可能陷入网络分区之类的情况，不知道外部已经产生了term更大的新的leader，拒绝。 至此，至少我们可以承认该leader的合法性，调用becomeFollower。 如果 m.Index \u0026gt; r.RaftLog.LastIndex() 这表示自己没有leader想要复制的日志的前一条日志，拒绝，并设置response消息中的index为自己的lastIndex。 如果m.Index对应的日志的term冲突，则拒绝，同时在response消息中需要附带上自己的日志中该term对应的第一条日志的index。 至此，同意复制日志。将消息中与自己冲突的日志全部附加在自身未冲突的日志项之后，更新stabled和commit。需要注意避免commit回退。  leader接收到其他peer对日志复制的回复后，在handleAppendEntriesResponse中处理。\n  若消息的term比自身的小，说明消息过期，拒绝。\n  如果消息类型是拒绝：\n 若m.Index为0，直接返回。 若m.LogTerm为0，说明该peer的日志落后自己太多。若不为0，说明该peer的日志和自己在prevIndex处冲突。调整r.Prs[m.From].Next，重新发送一次日志复制消息。    如果消息类型是接受：\n  更新r.Prs，视情况是否更新commit。若commit更新，需要立即广播AppendEntries。若该peer日志仍落后，需要再次发送日志复制。\n  Implement the raw node interface RawNode包装了一个Raft结构，是与上层应用交互的接口。Campaign函数让RawNode在raft层直接发起一次选举。Propose向raft层中添加一条日志。\nReady函数将此刻的RawNode状态相对于上一次调用Ready时的增量包装为一个Ready结构返回。其中：\n Ready.Entries表示未被持久化的日志项。 Ready.CommittedEntries表示已经commit未被apply的日志项。 Ready.Snapshot表示pendingSnapshot，此后需要清空pendingSnapshot。 Ready.Messages表示需要发给其他peer的消息，此后需要清空RawNode.Raft.msgs。 由于需要获取增量，所以HardState和SoftState需要与上一次获得的进行对比，若不同才能写入Ready中。因此，RawNode结构中需要记录prevSoftState、prevHardState。  hasReady用于判断Ready的增量是否存在。\nAdvance在上层应用处理完Ready后调用，更新raft层的stable、applied。\nPart B：构建一个可容错的KV服务 RaftStorage类似于StandaloneStorage，它处理用户发送来的请求。\n它启动一个Raftstore来驱动raft层，将请求包装为RaftCmdRequest，通过RaftstoreRouter发送给region中的leader，同时记录一个callback。raft层在日志复制到半数以上节点后apply，我们从callback中读出response，进行相应处理\nImplement peer storage 我们需要将Ready中的unstable entries持久化，需要注意几点\n 已经转化为快照的日志对应的index不能重复持久化。 已经持久化但过时的日志需要删除。  在SaveReadyState中我们要保存Ready中的状态，保存日志、更新PeerStorage.raftState，并持久化到raftDB。\nImplement Raft ready process Raftstore会启动一个raftWorker用于驱动raft层。它在一个循环中不停地接收消息，将一些消息调用RawNode的接口传递给raft层，并处理RawNode的Ready。\nfor _, msg := range msgs { peerState := rw.getPeerState(peerStateMap, msg.RegionID) if peerState == nil { continue } newPeerMsgHandler(peerState.peer, rw.ctx).HandleMsg(msg) } for _, peerState := range peerStateMap { newPeerMsgHandler(peerState.peer, rw.ctx).HandleRaftReady() } 首先实现proposeRaftCommand函数。它将RaftCmdRequest中的每一个Request与callback绑定，记录在peer.proposals数组中，并调用RawNode.Propose函数将请求发送到raft层进行共识。\n接着，实现HandleRaftReady函数。\n 若该peer已经被destroy，直接返回。 若该peer没有pending Ready，直接返回。 获取Ready，并调用SaveReadyState保存状态。如果自身是leader，调用HeartbeatScheduler向PD发送心跳同步状态。 调用Send发送消息给其他peer，处理Ready中的CommittedEntries，调用Advance。  在处理CommittedEntries时，对每个日志项使用一个WriteBatch来保证原子性。从entry.Data中Unmarshal出RaftCmdRequest结构，将其中的请求应用到状态机。需要注意的是请求类型为CmdType_Snap表示一个读事务，需要设置cb.Txn = d.peerStorage.Engines.Kv.NewTransaction(false)。\n将结果封装成RaftCmdResponse，从proposals中找到对应的callback返回。此后还需要更新peerStorage.applyState.AppliedIndex，一同加入WriteBatch，最后持久化。\n寻找对应的callback的过程在peerMsgHandler.handleProposal中实现。proposal的index和term和该请求在raft层中日志项的index和term是相同的，因此可以直接遍历proposals数组，找到对应的callback。若index相同但term不同说明这个请求可能未完成共识，应该调用NotifyStaleReq返回错误信息。\nPart C：raft 日志的垃圾回收以及快照 长时间运行的服务器会保存大量的raft日志，这会消耗大量磁盘空间。而且在许多时候我们只需要记录状态机的最终状态，而不需要保存状态机达到该状态所经历的过程，因此我们需要截断日志，进行日志项的垃圾回收，并通过快照同步到其他节点。\n我们需要在raft和raftstore两个部分中分别增加对快照的支持。\nImplement in Raft 在raft层的日志同步过程中，如果leader发现希望复制给follower的日志项已经被删除，应该转变为发送一个快照，并在此后复制剩余的日志项。\n首先我们修改Raft.sendAppend函数，leader调用这个函数以向follower复制日志。如果r.Prs[to].Next \u0026lt;= r.RaftLog.truncatedIndex，转为发送快照。调用r.RaftLog.storage.Snapshot以获取快照。\n接下来是Raft.handleSnapshot函数，follower在接收到leader发送的快照后调用这个函数处理。首先需要判断这个快照是否是最新的，如果meta.Index \u0026lt;= r.RaftLog.committed表示该快照不是最新，拒绝接收。之后follower接受这个快照，需要将applied、commited、stabled、truncatedIndex都修改为meta.Index，并清空本地的日志，将这个快照保存在RaftLog.pendingSnapshot中。还需要根据Metadate.ConfState.Nodes更新Raft.Prs。\npendingSnapshot会在Ready中被保存到raftstore中，需要实现PeerStorage.ApplySnapshot函数。先调用clearMeta和clearExtraData来清空过时的信息，然后更新raftState和applyState这些metadata，将snapState.StateType设置为SnapState_Applying。最后通过regionSched这个channel向region worker发送一个RegionTaskApply，等待其中的Notifier返回。在HandleRaftReady中需要先apply快照，后apply日志。\nImplement in raftstore raftstore会检查是否需要对日志项进行垃圾回收，并propose一个CompactLogRequest。\nCompactLogRequest在AdminRequest中，我们需要修改peerMsgHandler.proposeRaftCommand中增加对AdminRequest的处理。这个请求没有callback，因此不需要记录proposal，直接propose到raft层进行共识。\n经过共识的CompactLogRequest会在Ready中被apply，我们修改HandleRaftReady，在处理CommittedEntries先判断请求中AdminRequest是否为空，若不为空需要特殊处理。这个分支里目前只需要处理CompactLogRequest，先判断只有在adminReq.CompactLog.CompactIndex \u0026gt; d.peerStorage.applyState.TruncatedState.Index的时候才能compact。如果需要compact，首先更新 TruncatedState ，然后调用ScheduleCompactLog添加一个 raftlog-gc 的任务异步处理。\n","date":"2022-02-05T21:13:40+08:00","permalink":"https://ziannchen.work/2022/tinykv-project2-raftkv/","title":"TinyKV Project2: RaftKV"},{"content":"在本项目中，我们将在 column family 的支持下构建一个独立的 key / value 存储gRPC服务。在 kv/main.go 中我们初始化了一个 gRPC server，它包含了一个 tintkv.Server ，提供名为 TinyKV 的 gRPC 服务。\nserver := server.NewServer(storage) var alivePolicy = keepalive.EnforcementPolicy{ MinTime: 2 * time.Second, // If a client pings more than once every 2 seconds, terminate the connection  PermitWithoutStream: true, // Allow pings even when there are no active streams  } grpcServer := grpc.NewServer( grpc.KeepaliveEnforcementPolicy(alivePolicy), grpc.InitialWindowSize(1\u0026lt;\u0026lt;30), grpc.InitialConnWindowSize(1\u0026lt;\u0026lt;30), grpc.MaxRecvMsgSize(10*1024*1024), ) tinykvpb.RegisterTinyKvServer(grpcServer, server) 其中，server 依赖于一个 storage ，它是一个接口，可以根据配置文件选择raft存储实现或者单机存储实现。\n我们通过两步来完成这个项目：\n 实现一个单机存储引擎。 实现原始的kv服务handler。  实现一个单机存储引擎。 我们需要用一个单机存储引擎来实现这个接口：\n// Storage represents the internal-facing server part of TinyKV, it handles sending and receiving from other // TinyKV nodes. As part of that responsibility, it also reads and writes data to disk (or semi-permanent memory). type Storage interface { Start() error Stop() error Write(ctx *kvrpcpb.Context, batch []Modify) error Reader(ctx *kvrpcpb.Context) (StorageReader, error) } 代码位于 kv/storage/standalone_storage/standalone_storage.go 中。我们底层的存储服务使用了 badger ，因此实现 Storage 接口只需对 badger 的api进行封装。\ntype StandAloneStorage struct { // Your Data Here (1). \tdb *badger.DB } Reader 方法中直接返回一个 StandAloneStorageReader 即可，其中包含了一个 badger.Txn 是一个事务接口，提供了读时的快照。\nWrite 方法需要一次性 batch 中的所有写入或是删除操作写入数据库。需要使用一个 WriteBatch 记录下所有写操作，最后使用 WriteBatch.WriteToDB 方法一次性写入 badger。badger 并不支持 column family，因此tinykv在不同 column family 上的区分只是为把不同 column family 的key在编码时加上不同的前缀。\n实现原始的kv服务handler。 我们需要使用刚刚实现的单机存储引擎为 server 实现 RawGet/Put/Delete/Scan 4个方法。\nRawGet 方法需要使用 RawGetRequest 中的 Context 初始化一个 Reader，此后直接读取。\nRawPut/Delete 这两个写操作需要使用 storage.Modify 先进行封装再调用 Write 写入。\nRawScan 需要初始化一个迭代器 Reader.IterCF ，之后直接循环读取。\n","date":"2022-02-05T21:04:35+08:00","permalink":"https://ziannchen.work/2022/tinykv-project1-standalonekv/","title":"TinyKV Project1: StandaloneKV"},{"content":"lab课程网址 https://pdos.csail.mit.edu/6.824/labs/lab-shard.html\n本次lab是最难的一次lab，很多地方需要我们自由发挥，不像lab2那样可以参考论文。\nLab2和Lab3构成基础分布式数据库的框架，实现了多节点间的数据一致性，支持crud，数据同步和快照保存。然而，由于所有的请求都需要由 leader 来处理，当数据增长到一定程度时，若仍然使用单一集群服务所有数据，leader面对的压力会非常大，请求响应时间也会延长，磁盘空间也会不足。在这种模式下，增加机器并不会带来性能的提升，反而存在浪费。一个非常直接的解决方法，就是将数据按照某种方式分开存储到不同的集群上，将不同的请求引流到不同的集群，降低单一集群的压力，提供更为高效、更为健壮的服务。\nLab4就是要实现数据的划分，将不同的数据划分到不同的集群上，保证相应数据请求引流到对应的集群。这里，将互不相交并且组成完整数据的每一个数据子集称为 Shard。在同一阶段中，Shard 与集群的对应关系称为 Config，随着时间的推移，增加或减少机器、某个 Shard 中的数据请求过热，Shard 需要在不同集群之中进行迁移。如何在 Config更新、 Shard 迁移的同时仍能正确对外提供强一致性的服务，是lab4主要挑战。\n一个集群只有Leader才能服务，系统的性能与集群的数量成正比。lab3是一个集群，lab4要实现的是多个集群之间的配合。\n我画了一个 ShardKV 最终的结构图\n 图片 1 \nShardCtrler Client 在向 Server 发送RPC之前，需要先知道目标 key 所在的 Shard 位于哪一个 Group，以及如何和这个 Group 中的leader通信。这就需要有一个地方保存 shard -\u0026gt; gid 和 gid -\u0026gt; server 信息，这就是lab4A中需要实现的 ShardCtrler，它使用 Config 结构保存这些信息。\n// A configuration -- an assignment of shards to groups. // Please don\u0026#39;t change this. type Config struct { Num int // config number \tShards [NShards]int // shard -\u0026gt; gid \tGroups map[int][]string // gid -\u0026gt; servers[] } 每次 shard -\u0026gt; gid 的对应关系被更改时，ShardCtrler 创建一个新的 Config 保存新的对应关系。ShardCtrler 支持Join、Leave、Move、Query 4种RPC来添加新的 Group、删除 Group，在 Group 之间移动 Shard 以及查询对应 Num 的 Config，底层也使用Raft协议在多台机器上进行数据同步。因此整体实现和lab3类似。\nClient 为了简化逻辑4种请求共用一个RPC，也需要加上 ClientID 和 RequestID 让 server 端能够去重。\ntype CommandRequest struct { ClientID int RequestID int OpType JoinArgs LeaveArgs MoveArgs QueryArgs } type CommandResponse struct { Err Err Config Config } type JoinArgs struct { Servers map[int][]string // new GID -\u0026gt; servers mappings } type LeaveArgs struct { GIDs []int } type MoveArgs struct { Shard int GID int } type QueryArgs struct { Num int // desired config number } Server 对于RPC的处理模型和lab3是一样的，由于Config数据较小，还不用处理快照。\nJoin Join 操作向当前配置中新增一些server，这些server可能被加入现有的 Group 中，也可能是新增的 Group。\n新增的 Group 还没有 Shard，需要在 Groups 中对 Shards 进行平衡并且要产生尽可能少的 Shard 迁移，平衡的方法是每次循环让拥有 Shard 最多的 Group 分一个给拥有 Shard 最少的 Group，直到它们之间的差值小等于1。\nShardCtrler 刚启动时还没有 Config 信息，第一次执行 Join 时所有的 Shard 还未被分配到具体的 Group 上，对应的 gid 是0，我称为 zombieShard。因此在处理 Join 时也要分配可能存在的 zombieShard。此外maps数据需要深拷贝。\nfunc (sc *ShardCtrler) executeJoin(servers map[int][]string) { length := len(sc.configs) lastConfig := sc.configs[length-1] newGroups := deepCopy(lastConfig.Groups) for gid, servers := range servers { newGroups[gid] = servers } newConfig := Config{ Num: length, Shards: [NShards]int{}, Groups: newGroups, } groupToShards := getGroupToShards(newGroups, lastConfig.Shards) zombieShards := []int{} for shard, gid := range lastConfig.Shards { if gid == 0 { zombieShards = append(zombieShards, shard) } } for _, shard := range zombieShards { target := getMinGroup(groupToShards) groupToShards[target] = append(groupToShards[target], shard) } groupToShards = balanceShardBetweenGroups(groupToShards) for gid, shards := range groupToShards { for _, shard := range shards { newConfig.Shards[shard] = gid } } sc.configs = append(sc.configs, newConfig) } Leave Group 被删除后，其原先拥有的 Shard 就成了 zombieShard，应当依次分配被拥有 Shard 数量最少的 Group。\nfunc (sc *ShardCtrler) executeLeave(GIDs []int) { length := len(sc.configs) lastConfig := sc.configs[length-1] newGroups := deepCopy(lastConfig.Groups) newConfig := Config{ Num: length, Shards: [NShards]int{}, Groups: newGroups, } groupToShards := getGroupToShards(newGroups, lastConfig.Shards) zombieShards := []int{} for _, gid := range GIDs { delete(newConfig.Groups, gid) if shards, ok := groupToShards[gid]; ok { zombieShards = append(zombieShards, shards...) delete(groupToShards, gid) } } for _, shard := range zombieShards { target := getMinGroup(groupToShards) groupToShards[target] = append(groupToShards[target], shard) } for gid, shards := range groupToShards { for _, shard := range shards { newConfig.Shards[shard] = gid } } sc.configs = append(sc.configs, newConfig) } Move 将指定的 Shard 交由新的 Group 负责，只需要改动 Shards 数组。\nfunc (sc *ShardCtrler) executeMove(shard int, gid int) { length := len(sc.configs) lastConfig := sc.configs[length-1] newGroups := deepCopy(lastConfig.Groups) newConfig := Config{ Num: length, Shards: lastConfig.Shards, Groups: newGroups, } newConfig.Shards[shard] = gid sc.configs = append(sc.configs, newConfig) } Query Query 查询指定版本的 Config。\nfunc (sc *ShardCtrler) executeQuery(num int) Config { length := len(sc.configs) config := Config{} if num == -1 || num \u0026gt;= length { config = sc.configs[length-1] } else { config = sc.configs[num] } newGroups := deepCopy(config.Groups) newConfig := Config{ Num: config.Num, Shards: config.Shards, Groups: newGroups, } return newConfig } 测试结果 Test: Basic leave/join ... ... Passed Test: Historical queries ... ... Passed Test: Move ... ... Passed Test: Concurrent leave/join ... ... Passed Test: Minimal transfers after joins ... ... Passed Test: Minimal transfers after leaves ... ... Passed Test: Multi-group join/leave ... ... Passed Test: Concurrent multi leave/join ... ... Passed Test: Minimal transfers after multijoins ... ... Passed Test: Minimal transfers after multileaves ... ... Passed Test: Check Same config on servers ... ... Passed PASS ok 6.824/shardctrler\t5.641s ShardKV 整体结构 ShardKV 的状态机 db 由多个 Shard 组成，每个 Shard 包含了自己的状态、kv和客户端请求去重表，这使得不同的 Shard 之间可以在独立迁移的同时不影响未受影响的 Shard 对外正常提供服务，也可以通过 Shard 的状态来进行许多判断，每个状态的含义在注释中。\ntype ShardKV struct { mu sync.RWMutex me int rf *raft.Raft applyCh chan raft.ApplyMsg make_end func(string) *labrpc.ClientEnd gid int ctrlers []*labrpc.ClientEnd maxraftstate int // snapshot if log grows this big  // Your definitions here. \tprevConfig shardctrler.Config currConfig shardctrler.Config persister *raft.Persister scClerk *shardctrler.Clerk waitChs map[int]chan CommandResponse db map[int]*Shard lastAppliedIndex int } type ShardStatus int const ( // The group serves and owns the shard. \tServing ShardStatus = iota // The group serves the shard, but does not own the shard yet. \tPulling // The group does not serve and own the partition. \tInvalid // The group owns but does not serve the shard. \tErasing // The group own the shard and serve it, but it\u0026#39;s waiting for ex-owner to delete it \tWaiting ) type Shard struct { Status ShardStatus KV map[string]string LastSessions map[int]*Session } leader需要执行多个定时任务，需要在后台启动协程来循环判断状态、执行任务、睡眠。我抽象出了一个 daemon 函数来完成这些。\nfunc StartServer(servers []*labrpc.ClientEnd, me int, persister *raft.Persister, maxraftstate int, gid int, ctrlers []*labrpc.ClientEnd, make_end func(string) *labrpc.ClientEnd) *ShardKV { ··· // Your initialization code here.  // Use something like this to talk to the shardctrler: \t// kv.mck = shardctrler.MakeClerk(kv.ctrlers) \tkv.applyCh = make(chan raft.ApplyMsg) kv.rf = raft.Make(servers, me, persister, kv.applyCh) kv.scClerk = shardctrler.MakeClerk(kv.ctrlers) kv.mu = sync.RWMutex{} kv.waitChs = make(map[int]chan CommandResponse) kv.db = make(map[int]*Shard) for i := 0; i \u0026lt; shardctrler.NShards; i++ { kv.db[i] = \u0026amp;Shard{ Status: Invalid, KV: make(map[string]string), LastSessions: make(map[int]*Session), } } kv.lastAppliedIndex = -1 kv.prevConfig = shardctrler.Config{} kv.currConfig = shardctrler.Config{} kv.applySnapshot(persister.ReadSnapshot()) go kv.applier() go kv.daemon(kv.fetchConfig) go kv.daemon(kv.pullData) go kv.daemon(kv.eraseData) go kv.daemon(kv.proposeEmpty) return kv } func (kv *ShardKV) daemon(action func()) { for !kv.killed() { if _, isLeader := kv.rf.GetState(); isLeader { action() } time.Sleep(50 * time.Millisecond) } } applier 的结构和lab3类似，日志被 commit 之后根据 CommandType 的不同执行不同的applyxxx，其中 EraseData 和 ClientRequest 需要返回 response。\ntype CommandType int const ( ClientRequest CommandType = iota ConfChange InsertData EraseData StopWaiting Empty ) type RaftLogCommand struct { CommandType Data interface{} } func newRaftLogCommand(commandType CommandType, data interface{}) RaftLogCommand { return RaftLogCommand{ CommandType: commandType, Data: data, } } func (kv *ShardKV) applier() { for !kv.killed() { select { case applyMsg := \u0026lt;-kv.applyCh: if applyMsg.CommandValid { command := applyMsg.Command.(RaftLogCommand) kv.mu.Lock() if applyMsg.CommandIndex \u0026lt;= kv.lastAppliedIndex { DPrintf(\u0026#34;[Group %d][Server %d] discard out-of-date apply Msg [index %d]\u0026#34;, kv.gid, kv.me, applyMsg.CommandIndex) kv.mu.Unlock() continue } kv.lastAppliedIndex = applyMsg.CommandIndex response := \u0026amp;CommandResponse{} switch command.CommandType { case Empty: DPrintf(\u0026#34;[Group %d][Server %d] get empty in apply Msg [index %d]\u0026#34;, kv.gid, kv.me, applyMsg.CommandIndex) case ConfChange: lastestConf := command.Data.(shardctrler.Config) kv.applyConfChange(lastestConf, applyMsg.CommandIndex) case InsertData: resp := command.Data.(PullDataResponse) kv.applyInsertData(resp, applyMsg.CommandIndex) case StopWaiting: req := command.Data.(EraseDataRequest) kv.applyStopWaiting(req, applyMsg.CommandIndex) case EraseData: req := command.Data.(EraseDataRequest) response = kv.applyEraseData(req, applyMsg.CommandIndex) if currentTerm, isLeader := kv.rf.GetState(); currentTerm == applyMsg.CommandTerm \u0026amp;\u0026amp; isLeader { ch := kv.getWaitCh(applyMsg.CommandIndex) ch \u0026lt;- *response } case ClientRequest: request := command.Data.(CommandRequest) response = kv.applyClientRequest(\u0026amp;request, applyMsg.CommandIndex) if currentTerm, isLeader := kv.rf.GetState(); currentTerm == applyMsg.CommandTerm \u0026amp;\u0026amp; isLeader { ch := kv.getWaitCh(applyMsg.CommandIndex) ch \u0026lt;- *response } } if kv.needToSnapshot(applyMsg.RaftStateSize) { DPrintf(\u0026#34;[Group %d][Server %d] take a snapshot till [index %d]\u0026#34;, kv.gid, kv.me, applyMsg.CommandIndex) kv.takeSnapshot(applyMsg.CommandIndex) } kv.mu.Unlock() } else { kv.mu.Lock() DPrintf(\u0026#34;[Group %d][Server %d] received a snapshot from raft layer [index %d]\u0026#34;, kv.gid, kv.me, applyMsg.SnapshotIndex) if kv.rf.CondInstallSnapshot(applyMsg.SnapshotTerm, applyMsg.SnapshotIndex, applyMsg.Snapshot) { kv.applySnapshot(applyMsg.Snapshot) kv.lastAppliedIndex = applyMsg.SnapshotIndex } kv.mu.Unlock() } } } } 客户端请求 这里和lab3基本一样，不同的是 handle RPC 以及日志apply时都需要额外判断在当前版本的 Config 下本 Group 是否负责该 key 所属的 Shard。\nfunc (kv *ShardKV) isShardMatch(shardId int) bool { return kv.currConfig.Shards[shardId] == kv.gid \u0026amp;\u0026amp; (kv.db[shardId].Status == Serving || kv.db[shardId].Status == Waiting) } 配置更新 每个 Group 中的 leader 需要在后台启动一个协程向 ShardCtrler 定时使用 Query 拉取最新的 Config，一旦拉取到就需要提交一条 raft 日志，以在每台机器上更新配置。\n此外，每次只能拉取高一个版本的配置，而且为了防止集群的分片状态被覆盖，从而使得某些任务永远不会被执行，只有在每一 Shard 的状态都为 Serving 或 Invalid 时才能拉取、更新配置。\nfunc (kv *ShardKV) fetchConfig() { canFetchConf := true kv.mu.RLock() currConfNum := kv.currConfig.Num for shardId, shard := range kv.db { if shard.Status != Serving \u0026amp;\u0026amp; shard.Status != Invalid { canFetchConf = false break } } kv.mu.RUnlock() if canFetchConf { latestConfig := kv.scClerk.Query(currConfNum + 1) if latestConfig.Num == currConfNum+1 { kv.rf.Start(newRaftLogCommand(ConfChange, latestConfig)) } } } 在每台机器上，新配置对应的 raft 日志被 commit 之后，都需要更新本地的 prevConfig 和 currConfig，以及更新 db 中对应的 Shard 状态，以便让数据拉取、数据清理协程能检测到去进行数据迁移。\n在新版本的 Config 中新增的 Shard 状态改为 Pulling，等待拉取数据协程去其他 Group 上拉数据。失去的 Shard 状态改为 Erasing，等待其他 Group 来拉取数据。若当前 Config 的版本为1，则代表集群刚初始化，不需要去其他 Group 拉取数据，只需更改对应的 Shard 状态为 Serving。\n数据拉取 新的 Config 在 applier 协程中被应用并不表示所属分片可以立刻对外提供服务，还需要等待在上一个版本的 Config 中不属于自身的 Shard 从它之前所属的 Group 中迁移到本 Group。\n这里显然不能在配置更新时同步阻塞的去拉取 Shard，这会阻塞 applier 协程，严重影响对外服务的可用性。那么是否可以异步的去拉取数据并提交日志？其实不行，leader 可能会在 apply 新配置之后到新数据被异步拉取到并提交日志之前宕机，而 follower 虽然会 apply 配置但是不会去拉数据，这样这些数据将永远无法被更新。\n因此，我们不能在 apply 配置的时候启动异步任务，而是应该只更新 shard 的状态，由单独的后台协程去检测每个 Shard 的状态，从而判断是否需要并执行分片迁移，分片清理等任务。为了让单独的协程能知道该向哪个 Group 去拉取数据或让它去删除数据，ShardKV 需要维护 currConfig 和 prevConfig，这样其他协程能够通过它们来得知所有 Shard 的 ex-owner。\n需要定义新的RPC来完成数据拉取。\ntype PullDataRequest struct { ConfNum int ShardIds []int } type PullDataResponse struct { Err Err ConfNum int Shards map[int]*Shard } 并行向状态为 Pulling 的不同 Shard 的 ex-owner 发送RPC来拉取数据，使用 waitGroup 来保证尝试拉取了一遍当前版本的配置所需要的所有 Shard 之后才能进行下一轮循环。\nfunc (kv *ShardKV) pullData() { kv.mu.RLock() groupToShards := kv.getGroupToShards(Pulling) currConfNum := kv.currConfig.Num wg := sync.WaitGroup{} for gid, shards := range groupToShards { wg.Add(1) servers := kv.prevConfig.Groups[gid] go func(servers []string, shards []int, confNum int) { defer wg.Done() for _, server := range servers { shardOwner := kv.make_end(server) args := PullDataRequest{ ConfNum: confNum, ShardIds: shards, } reply := PullDataResponse{} if shardOwner.Call(\u0026#34;ShardKV.PullData\u0026#34;, \u0026amp;args, \u0026amp;reply) \u0026amp;\u0026amp; reply.Err == OK { kv.rf.Start(newRaftLogCommand(InsertData, resp)) break } } }(servers, shards, currConfNum) } kv.mu.RUnlock() wg.Wait() } 数据的被拉取方在处理 RPC 时，只有在 PullDataRequest 中的配置版本与自身的配置版本相同时，才回应其需要的 Shard 信息。需要注意正确的对所有 Shard 深拷贝。\nfunc (kv *ShardKV) PullData(args *PullDataRequest, reply *PullDataResponse) { defer DPrintf(\u0026#34;[Group %d][Server %d] reply %s for PULL DATA request %s\u0026#34;, kv.gid, kv.me, reply, args) DPrintf(\u0026#34;[Group %d][Server %d] received a PULL DATA request %s\u0026#34;, kv.gid, kv.me, args) if _, isLeader := kv.rf.GetState(); !isLeader { reply.Err = ErrWrongLeader return } kv.mu.RLock() defer kv.mu.RUnlock() if kv.currConfig.Num \u0026lt; args.ConfNum { reply.Err = ErrNotReady return } if kv.currConfig.Num \u0026gt; args.ConfNum { panic(\u0026#34;duplicated pull data request\u0026#34;) } replyShards := make(map[int]*Shard) for _, shardId := range args.ShardIds { shard := kv.db[shardId] replyShards[shardId] = deepCopyShard(shard) } reply.ConfNum = kv.currConfig.Num reply.Shards = replyShards reply.Err = OK } 在 applyInsertData 时，为了保证集群数据变更的幂等性，要保证 Config 的版本与当前版本相同时以及其 Shard 的本地状态为 Pulling 时才能更新 Shard 的状态。将其状态改为 Waiting 让数据清理协程去检测。\n数据清理 current owner 在完成数据拉取之后，需要清理掉每个新拉到的 Shard 对应的 ex-owner 机器上的旧数据。后台协程检查所有状态为 Waiting 的 Shard，并行向它们的 ex-owners 分别发送 RPC，告知它们：我已拉取到我要的数据，现在你可以把它们（对应的 Shard 状态为 Erasing）删了。这里 waitGroup 的用法同上。\nRPC返回且得知 ex-owners 上的数据清理已经完成后需要提交一条 StopWaiting 类型的 raft 日志，将这个信息同步到 Group 内所有机器上。\ntype EraseDataRequest struct { ConfNum int ShardIDs []int } type EraseDataResponse struct { Err Err } func (kv *ShardKV) eraseData() { kv.mu.RLock() groupToShards := kv.getGroupToShards(Waiting) currConfNum := kv.currConfig.Num wg := sync.WaitGroup{} for gid, shards := range groupToShards { wg.Add(1) servers := kv.prevConfig.Groups[gid] go func(servers []string, shards []int, confNum int) { defer wg.Done() for _, server := range servers { shardOwner := kv.make_end(server) args := EraseDataRequest{ ConfNum: confNum, ShardIDs: shards, } reply := EraseDataResponse{} if shardOwner.Call(\u0026#34;ShardKV.EraseData\u0026#34;, \u0026amp;args, \u0026amp;reply) \u0026amp;\u0026amp; reply.Err == OK { kv.rf.Start(newRaftLogCommand(StopWaiting, req)) break } } }(servers, shards, currConfNum) } kv.mu.RUnlock() wg.Wait() } StopWaiting 日志以及 Shard 的 Waiting 状态存在的用途是标记我是否已经成功在 ex-owner 上删除过期的 Shard。applyStopWaiting 时，在 Config 版本相同时将对应的状态为 Waiting 的 Shard 更新状态为 Serving。\nex-owner ex-owner 在 handle EraseData 的RPC时，需要返回数据清理是否完成，这里的处理类似处理客户端请求，不需要进行去重。\nfunc (kv *ShardKV) EraseData(req *EraseDataRequest, resp *EraseDataResponse) { defer DPrintf(\u0026#34;[Group %d][Server %d] resp %s for ERASE DATA request %s\u0026#34;, kv.gid, kv.me, resp, req) DPrintf(\u0026#34;[Group %d][Server %d] received a ERASE DATA request %s\u0026#34;, kv.gid, kv.me, req) index, _, isLeader := kv.rf.Start(newRaftLogCommand(EraseData, *req)) if !isLeader { resp.Err = ErrWrongLeader return } kv.mu.Lock() ch := kv.getWaitCh(index) kv.mu.Unlock() select { case response := \u0026lt;-ch: resp.Err = response.Err case \u0026lt;-time.NewTimer(500 * time.Millisecond).C: resp.Err = ErrTimeout } go func() { kv.mu.Lock() kv.removeWaitCh(index) kv.mu.Unlock() }() } apply 时，在版本号相同的情况下将对应的状态为 Erasing 的 Shard 更新为 Invalid，表明对应 Shard 已经成功被清除，清空 kv 和客户端请求去重表。不要忘了返回OK。\n提交空日志 在某个涉及重启的测试中，有时候会出现集群对外出现活锁，无法再服务请求直到超时。我重新打了很多日志，发现这时各个 Group 间的 Config 版本不一致，且版本较低的 Group 的一些 Shard 状态不为 Serving 和 Invalid，这卡着配置更新协程无法拉取最新的 Config。按理说 Config 的版本只能以1为公差递增，其余的 Group 版本高说明也经历过较低的这个版本，应该有向这个 Group 发送过拉取数据和清理数据的RPC来更新 Shard 状态，那么为什么状态并没有被更新呢？\n仔细读了很久日志，我发现版本较低的 Group 在推进 Config 到这个版本之后已经正确处理过拉取数据或是清理数据的RPC也更新了 Shard 状态，但在重启后这最后处理的关键RPC对应的日志并没有重新被commit。原来，此时 leader 的 currentTerm 高于这个RPC对应的日志的 term，且这个时间节点客户端碰巧没有向该 Group 组执行读写请求，导致 leader 无法拥有当前任期的 term 的日志，无法将状态机更新到最新。\nlab4的最后一部分是我在写完 TinyKV 之后做的，我想到 TinyKV （其实 etcd 也是这么做的）中要求的 leader 在当选时要先提交一条空日志，这样可以保证集群的可用性，于是我也移植了这个特性到 6.824 中。\n想起了以前几个月前看过的 谭新宇 的文章，我知道了不能把这个特性加到 raft 层。于是我也让 leader 在 kv 层周期性的去检测下层是否包含当前 term 的日志，如果没有便 append 一条空日志，这样即可保证新选出的 leader 状态机能够迅速达到最新。\nfunc (kv *ShardKV) proposeEmpty() { if !kv.rf.HasLogAtCurrentTerm() { kv.rf.Start(newRaftLogCommand(Empty, nil)) } } 测试结果 Test: static shards ... ... Passed Test: join then leave ... ... Passed Test: snapshots, join, and leave ... ... Passed Test: servers miss configuration changes... ... Passed Test: concurrent puts and configuration changes... ... Passed Test: more concurrent puts and configuration changes... ... Passed Test: concurrent configuration change and restart... ... Passed Test: unreliable 1... ... Passed Test: unreliable 2... ... Passed Test: unreliable 3... ... Passed Test: shard deletion (challenge 1) ... ... Passed Test: unaffected shard access (challenge 2) ... ... Passed Test: partial migration shard access (challenge 2) ... ... Passed PASS ok 6.824/shardkv\t108.040s ","date":"2022-02-04T13:21:03+08:00","permalink":"https://ziannchen.work/2022/mit-6.824-lab4-shardkv/","title":"mit-6.824 lab4: ShardKV"},{"content":"Lab3: KVRaft lab链接 https://pdos.csail.mit.edu/6.824/labs/lab-kvraft.html\n本次lab中我们需要使用lab2中实现的Raft库来构建一个可容错的 Key/Value 存储服务，要求其对外提供强一致性（Strong consistency）。\n这个KV存储服务支持Get/Put/Append三种客户端操作。客户端通过RPC与集群中的leader通信，leader接收到请求后将其包装在一条Raft日志中下放到Raft层进行共识，日志被apply后返回客户端结果。\n一些思考 在PartA的描述中提到，leader在将一个请求下放到raft层之后，commit之前宕机，这时它无法回复Clerk。又或者是，这条日志成功commit，但返回的RPC丢失。Clerk在规定时间内没有收到结果，会向另一台主机（可能是新选出的leader）发送RPC，这条日志最终被commit之后又会被应用于状态机，从而状态机执行了两次相同的请求。\n这要求我们能够判断重复的请求。因此每个请求都需要被唯一标识，请求中需要加上（ClientID, RequestID），Clerk每次请求成功之后自增RequestID。\n我们还需要在遇到重复的请求时直接返回第一次请求时的结果，这需要我们保存每一个Clerk的最后一次请求的结果ClientID -\u0026gt; (RequestID, LastResponse)。只需要保存最后一次请求结果是因为如果服务端收到RequestID = x的RPC，说明这个Clerk已经收到了RequestID为[1, x-1]之间内的所有请求的结果，服务端如果再次收到这个RequestID在区间之内的请求说明该RPC过期，直接丢弃即可。\nclient 我将3种请求共用了一个RPC，简化了逻辑。\nClerk保存一个leaderID，请求失败了再换另一个server，请求成功了自增requestID。\ntype Clerk struct { servers []*labrpc.ClientEnd // You will have to modify this struct. \tleaderID int clientID int64 requestID int } func (ck *Clerk) Get(key string) string { return ck.Command(key, \u0026#34;\u0026#34;, OpGet) } func (ck *Clerk) Put(key string, value string) { ck.Command(key, value, OpPut) } func (ck *Clerk) Append(key string, value string) { ck.Command(key, value, OpAppend) } func (ck *Clerk) Command(key, value string, op Operation) string { req := getCommandRequest(key, value, op, int(ck.clientID), ck.requestID)\tfor { resp := CommandResponse{} if !ck.servers[ck.leaderID].Call(\u0026#34;KVServer.Command\u0026#34;, \u0026amp;req, \u0026amp;resp) || resp.Err == ErrWrongLeader || resp.Err == ErrTimeout {\tck.leaderID = (ck.leaderID + 1) % len(ck.servers) continue } ck.requestID++ return\tresp.Value\t} } server KVServer的结构体如下：\ntype KVServer struct { mu sync.RWMutex me int rf *raft.Raft applyCh chan raft.ApplyMsg dead int32 // set by Kill()  maxraftstate int // snapshot if log grows this big  // Your definitions here. \tpersister *raft.Persister waitChs map[int]chan *CommandResponse db map[string]string lastSessions map[int]Session lastAppliedIndex int } state-machine 本次lab中只需使用一个内存版本的 KV 状态机 map[string]string。\nRPC handler 客户端请求来临时，Server端会启动一个协程作为 RPC handler 来处理客户端请求，其中会调用 Raft.Start 函数将请求下放到 Raft 层形成一条日志去做共识。在 Raft 层，每条被commit的日志会按照 index 的顺序写入 applyCh 中，上层必须也按 index 序从applyCh中读出日志并应用于状态机，这样才能保证不同节点上的数据一致。\n这要求必须有一个单独的applier协程来循环读applyCh，并应用于状态机。由于来自不同客户端的请求是并发的，如果在RPC handler协程中直接读applyCh无法保证index序。返回给客户端的response要根据日志应用于状态机的结果来生成，这需要我们处理RPC handler和applier协程之间的通信问题。\n自然想到使用channel来通信，使用一个 waitChs map (log index -\u0026gt; response) 来记录每一个请求对应的channel。在RPC handler协程将日志下放到Raft层之后，在 waitChs 中注册一个channel并阻塞读，applier协程读出日志，应用于状态机之后生成response写入这个channel。RPC handler协程在规定时间内读出结果则正常返回客户端，若超时则返回超时。\nfunc (kv *KVServer) Command(req *CommandRequest, resp *CommandResponse) { // Your code here. \tkv.mu.RLock() defer DPrintf(\u0026#34;[KVServer %d] reply %+v for Request %+v\u0026#34;, kv.me, resp, req) DPrintf(\u0026#34;[KVServer %d] received Request %+v from Clerk\u0026#34;, kv.me, req) if req.Op != OpGet \u0026amp;\u0026amp; kv.isDuplicatedRequest(req.ClientID, req.RequestID) { resp.Err = kv.lastSessions[req.ClientID].Err kv.mu.RUnlock() return } kv.mu.RUnlock() index, _, isLeader := kv.rf.Start(*req) if !isLeader { resp.Err = ErrWrongLeader return } DPrintf(\u0026#34;[KVServer %d] add command into raft layer [index %d]\u0026#34;, kv.me, index) kv.mu.Lock() ch := kv.getWaitCh(index) kv.mu.Unlock() select { case result := \u0026lt;-ch: resp.Value = result.Value resp.Err = result.Err case \u0026lt;-time.NewTimer(500 * time.Millisecond).C: resp.Err = ErrTimeout } go func() { kv.mu.Lock() kv.removeWaitCh(index) kv.mu.Unlock() }() } func (kv *KVServer) applier() { for !kv.killed() { select { case applyMsg := \u0026lt;-kv.applyCh: if applyMsg.CommandValid { command := applyMsg.Command.(CommandRequest) kv.mu.Lock() if applyMsg.CommandIndex \u0026lt;= kv.lastAppliedIndex { DPrintf(\u0026#34;[KVServer %d] discard out-of-date apply Msg in [index %d]\u0026#34;, kv.me, applyMsg.CommandIndex) kv.mu.Unlock() continue } kv.lastAppliedIndex = applyMsg.CommandIndex var response *CommandResponse if command.Op != OpGet \u0026amp;\u0026amp; kv.isDuplicatedRequest(command.ClientID, command.RequestID) { DPrintf(\u0026#34;[KVServer %d] received a duplicated command in [index %d]\u0026#34;, kv.me, applyMsg.CommandIndex) response = kv.lastSessions[command.ClientID].CommandResponse } else { response = kv.applyCommand(command) if command.Op != OpGet { kv.lastSessions[command.ClientID] = Session{ RequestID: command.RequestID, CommandResponse: response, } } } if kv.needToSnapshot(applyMsg.RaftStateSize) { DPrintf(\u0026#34;[KVServer %d] reach maxraftstate, take a snapshot till [index %d]\u0026#34;, kv.me, applyMsg.CommandIndex) kv.takeSnapshot(applyMsg.CommandIndex) } if currentTerm, isLeader := kv.rf.GetState(); currentTerm == applyMsg.CommandTerm \u0026amp;\u0026amp; isLeader { ch := kv.getWaitCh(applyMsg.CommandIndex) ch \u0026lt;- response } kv.mu.Unlock() } else { kv.mu.Lock() DPrintf(\u0026#34;[KVServer %d] received a snapshot from raft layer [index %d, term %d]\u0026#34;, kv.me, applyMsg.SnapshotIndex, applyMsg.SnapshotTerm) if kv.rf.CondInstallSnapshot(applyMsg.SnapshotTerm, applyMsg.SnapshotIndex, applyMsg.Snapshot) { kv.applySnapshotToService(applyMsg.Snapshot) kv.lastAppliedIndex = applyMsg.SnapshotIndex } kv.mu.Unlock() } } } } 有几点需要注意：\n  apply日志时需要防止状态机回滚。在lab2中提到作为follower的节点可能收到leader的install snapshot，将snapshot写入applyCh中，此时读applyCh的顺序是：旧日志1 -\u0026gt; 新快照 -\u0026gt; 旧日志2。应用了新快照之后要避免再次应用旧日志，所以应用快照之后也要更新 lastAppliedIndex，应用日志时要先判断是否 applyMsg.CommandIndex \u0026lt;= kv.lastAppliedIndex。\n  仅对leader的waitCh进行通知。每个节点在读出日志后都要提交到状态机，且更新lastSessions。但只有leader需要将response写入waitCh。leader可能会在提交日志后失去leader身份，所以在applier中写入response前要先判断。此时RPC handler协程就让其超时。\n  客户端的非读请求需要两次去重。重复的请求到来时，之前相同的请求可能已经被应用于该节点的状态机，也可能其对应的日志还没被commit。因此需要在RPC handler中调用Start之前以及日志commit之后应用于状态机之前两次去重。\n  leader在调用Start提交日志后去获取waitCh来阻塞读 以及 applier 在commit日志并应用于状态机之后获取waitCh来写入response 这二者之间顺序无法保证。因此channel容量设置为1，先获取channel的协程要负责创建channel，这个过程要加写锁。\n  func (kv *KVServer) getWaitCh(index int) chan *CommandResponse { ch, ok := kv.waitChs[index] if !ok { ch := make(chan *CommandResponse, 1) kv.waitChs[index] = ch return ch } return ch } snapshot part B中要求我们在raft state size达到阈值时给raft层下发快照。快照中不仅需要包含KV状态机，还需要包含lastSessions客户端请求去重表。由于快照是和lastIncludeIndex对应的，所以需要由applier协程在将对应的index的日志应用于状态机后继续阻塞的生成快照。\n测试结果 3A Test: one client (3A) ... ... Passed -- 15.1 5 9881 941 Test: ops complete fast enough (3A) ... ... Passed -- 15.5 3 7032 0 Test: many clients (3A) ... ... Passed -- 15.6 5 11160 1171 Test: unreliable net, many clients (3A) ... ... Passed -- 16.2 5 7462 901 Test: concurrent append to same key, unreliable (3A) ... ... Passed -- 1.5 3 282 52 Test: progress in majority (3A) ... ... Passed -- 1.1 5 108 2 Test: no progress in minority (3A) ... ... Passed -- 1.0 5 184 3 Test: completion after heal (3A) ... ... Passed -- 1.0 5 63 3 Test: partitions, one client (3A) ... ... Passed -- 22.5 5 9323 643 Test: partitions, many clients (3A) ... ... Passed -- 23.3 5 18230 837 Test: restarts, one client (3A) ... ... Passed -- 22.0 5 12689 822 Test: restarts, many clients (3A) ... ... Passed -- 22.9 5 24109 1144 Test: unreliable net, restarts, many clients (3A) ... ... Passed -- 25.7 5 9398 873 Test: restarts, partitions, many clients (3A) ... ... Passed -- 30.3 5 19984 848 Test: unreliable net, restarts, partitions, many clients (3A) ... ... Passed -- 29.9 5 7443 622 Test: unreliable net, restarts, partitions, random keys, many clients (3A) ... ... Passed -- 32.9 7 14185 904 PASS ok 6.824/kvraft\t277.625s 3B Test: InstallSnapshot RPC (3B) ... ... Passed -- 3.4 3 2151 63 Test: snapshot size is reasonable (3B) ... ... Passed -- 2.8 3 5727 800 Test: ops complete fast enough (3B) ... ... Passed -- 3.2 3 6962 0 Test: restarts, snapshots, one client (3B) ... ... Passed -- 21.2 5 46519 4431 Test: restarts, snapshots, many clients (3B) ... ... Passed -- 21.6 5 53053 4531 Test: unreliable net, snapshots, many clients (3B) ... ... Passed -- 15.9 5 11057 1341 Test: unreliable net, restarts, snapshots, many clients (3B) ... ... Passed -- 22.3 5 12478 1412 Test: unreliable net, restarts, partitions, snapshots, many clients (3B) ... ... Passed -- 29.6 5 8653 760 Test: unreliable net, restarts, partitions, snapshots, random keys, many clients (3B) ... ... Passed -- 31.6 7 25416 1802 PASS ok 6.824/kvraft\t151.660s ","date":"2022-02-03T15:06:21+08:00","permalink":"https://ziannchen.work/2022/mit-6.824-lab3-raftkv/","title":"mit-6.824 lab3: RaftKV"},{"content":"Lab2: Raft lab原链接 https://pdos.csail.mit.edu/6.824/labs/lab-raft.html\nRaft是一种基于复制的状态机协议，通过在多个副本服务器上存储其状态（即数据）的完整副本来实现容错。\nRaft将客户端请求组织成一个称为日志的序列，并通过复制确保所有副本服务器都看到相同的日志。每个副本按日志顺序执行客户端请求，并将它们应用于本地的状态机副本。由于所有副本服务器都看到相同的日志内容，因此它们都以相同的顺序执行相同的请求，从而继续具有相同的服务状态。如果服务器出现故障但随后恢复，Raft保证只要至少半数的服务器存活，并且可以相互通信，就可以保证正常对外服务。\n在本次lab中我们的任务是使用go语言实现raft。参考论文 raft-extended，我们需要实现除了集群成员变更之外的绝大部分内容。论文中我认为最核心的就是描述3个RPC的(Figure 2)这张图，我的实现大体上遵循了这张图。此外我也参考了一些工业级的raft实现，比如SOFAJraft、etcd，做了一些优化。在我秋招面试美团的一个做分布式存储的部门时，他们问了我很多关于raft的内容（虽然最后挂了）。\n有些需要注意的点：\n 当收到的RPC中的term大于自身时，无条件跟随term并转为follower，这在不同的RPC handler中的处理略有不同。 在lab的一些测试用例中，网络将是不稳定的，带来大量随机的RPC丢包、乱序、超时。对于过期的RPC，直接抛弃不处理即可。对于是否过期的判断体现在term太小、身份不正确之类（例如follow收到append entries response）。 锁的使用：在接发RPC、读写channel时一定不要持有锁，不然很有可能死锁。此外有许多代码块对Raft结构中各字段是只读的，我使用了读写锁。  结构体 Raft结构中的各个变量和论文大致一样。\ntype Raft struct { rw sync.RWMutex // Lock to protect shared access to this peer\u0026#39;s state \tpeers []*labrpc.ClientEnd // RPC end points of all peers \tpersister *Persister // Object to hold this peer\u0026#39;s persisted state \tme int // this peer\u0026#39;s index into peers[] \tdead int32 // set by Kill() \t// Your data here (2A, 2B, 2C). \t// Look at the paper\u0026#39;s Figure 2 for a description of what \t// state a Raft server must maintain.  currentState State currentTerm int votedFor int voteFrom map[int]bool logs []LogEntry commitIndex int lastApplied int nextIndex []int matchIndex []int electionTimer *time.Timer heartbeatTimer *time.Timer applyCh chan ApplyMsg applierCond sync.Cond replicatorCond []sync.Cond } func Make(peers []*labrpc.ClientEnd, me int, persister *Persister, applyCh chan ApplyMsg) *Raft { // Your initialization code here (2A, 2B, 2C). \trf := \u0026amp;Raft{ rw: sync.RWMutex{}, peers: peers, persister: persister, me: me, dead: -1, currentState: Follower, currentTerm: 0, votedFor: -1, voteFrom: make(map[int]bool), logs: make([]LogEntry, 1), nextIndex: make([]int, len(peers)), matchIndex: make([]int, len(peers)), electionTimer: time.NewTimer(RandomizedElectionTimeout()), heartbeatTimer: time.NewTimer(StableHeartbeatTimeout()), applyCh: applyCh, replicatorCond: make([]sync.Cond, len(peers)), } rf.applierCond = *sync.NewCond(\u0026amp;rf.rw) rf.logs[0] = LogEntry{0, 0, nil} // initialize from state persisted before a crash \trf.readPersist(persister.ReadRaftState()) rf.commitIndex, rf.lastApplied = rf.logs[0].Index, rf.logs[0].Index for i := 0; i \u0026lt; len(peers); i++ { rf.matchIndex[i], rf.nextIndex[i] = 0, rf.getLastLogEntry().Index+1 if i == me { continue } rf.replicatorCond[i] = *sync.NewCond(\u0026amp;sync.Mutex{}) go rf.replicator(i) } // start ticker goroutine to start elections \tgo rf.ticker() go rf.applier(rf.applyCh) return rf } 根据论文，日志的index和term都从1开始，所以在logs[0]处存放一个index和term均为0的dummy value。\n在Make函数中启动了一些后台协程\n replicator：共len(peers)-1个，用于管理leader对每一个follower的日志复制，下文会详细介绍。 ticker：用来触发选举和心跳timeout。 applier：用于向applyCh中提交已经commit的日志。  leader-election sender 在ticker函数中需要循环使用select监听两个timer的channel，lab的提示中说使用timer可能会有问题但我没有遇到过，懒得改了。\n如果是选举计时器到期，则发起一轮选举；如果是心跳计时器到期，则发起一轮心跳。二者都要首先判断当前身份是否正确。我使用了一个map来记录当前term中投票给自己的peer，需要在每次转换为candidate时清空map。也可以每次start election时声明一个得票计数，之后使用闭包来计算。\nfunc (rf *Raft) ticker() { for !rf.Killed() { select { case \u0026lt;-rf.electionTimer.C: rf.rw.Lock() if rf.currentState != Leader { rf.currentState = Candidate rf.voteFrom = make(map[int]bool) rf.currentTerm++ rf.startElection() } rf.electionTimer.Reset(RandomizedElectionTimeout()) rf.rw.Unlock() case \u0026lt;-rf.heartbeatTimer.C: rf.rw.Lock() if rf.currentState == Leader { DPrintf(\u0026#34;[Server %d] boardcast heartbeat at term %d\u0026#34;, rf.me, rf.currentTerm) rf.boardcastHeartbeat(true) } rf.rw.Unlock() } } } 选举需要异步对每个peer发送request vote，不然就太慢了。异步才不会阻塞ticker，能快速重置计时器。response handler中要先判断是否仍满足rf.currentTerm == args.Term \u0026amp;\u0026amp; rf.currentState == Candidate，若不满足说明RPC过期，直接抛弃不处理。\n我之所以没有使用闭包是因为这样难以抽象出一个 handleRequestVoteResponse 函数，代码结构不够统一。\nfunc (rf *Raft) startElection() { args := rf.getDefaultRequestVoteArgs() rf.votedFor, rf.voteFrom[rf.me] = rf.me, true rf.persist() DPrintf(\u0026#34;[Server %d] start election at term %d\u0026#34;, rf.me, rf.currentTerm) for index := range rf.peers { if index == rf.me { continue } go func(i int) { reply := RequestVoteReply{} if rf.sendRequestVote(i, \u0026amp;args, \u0026amp;reply) { rf.rw.Lock() rf.handleRequestVoteResponse(i, \u0026amp;args, \u0026amp;reply) rf.rw.Unlock() } }(index) } } handler handler的实现完全参照论文，先判断term是否小于自身，再判断term、voteFor和日志是否满足条件。判断voteFor时要先满足args.Term == rf.currentTerm，这是由于args.Term \u0026gt; rf.currentTerm时需要无条件跟随term并重置voteFor。\n需要注意的是只有同意投票时才需要重置election timer，这在课程的TA的guidance中有提及，有利于在网络不稳定时仍能快速选出leader。\nfunc (rf *Raft) RequestVote(args *RequestVoteArgs, reply *RequestVoteReply) { // Your code here (2A, 2B). \tdefer rf.rw.Unlock() defer DPrintf(\u0026#34;[Server %d] reply [%s] for RequestVote to %d\u0026#34;, rf.me, reply, args.CandidateId) rf.rw.Lock() DPrintf(\u0026#34;[Server %d][state %s term %d vote %d lastindex %d lastterm %d] receive RequestVote [%s] from %d\u0026#34;, rf.me, StateName[rf.currentState], rf.currentTerm, rf.votedFor, rf.getLastLogEntry().Index, rf.getLastLogEntry().Term, args, args.CandidateId) if args.Term \u0026lt; rf.currentTerm || (args.Term == rf.currentTerm \u0026amp;\u0026amp; rf.votedFor != -1 \u0026amp;\u0026amp; rf.votedFor != args.CandidateId) { reply.Term, reply.VoteGranted = rf.currentTerm, false return } needToPersist := false if args.Term \u0026gt; rf.currentTerm { rf.currentTerm, rf.votedFor = args.Term, -1 DPrintf(\u0026#34;[Server %d] change state from Leader to Follower at term %d\u0026#34;, rf.me, rf.currentTerm) rf.currentState = Follower needToPersist = true } if !rf.isLogUpToDate(args.LastLogIndex, args.LastLogTerm) { reply.Term, reply.VoteGranted = rf.currentTerm, false if needToPersist { rf.persist() } return } reply.Term, reply.VoteGranted = rf.currentTerm, true rf.votedFor = args.CandidateId rf.persist() rf.electionTimer.Reset(RandomizedElectionTimeout()) } log-replication replicator 根据每个peer的nextIndex判断发送entries或是snapshot。\nresponse handler的实现参照论文，先判断是否过期，再判断是否成功。若成功，则更新match、next index。找到最新的复制到超过半数peer且term等于当前term的日志，更新commit。需要注意日志的term必须和当前term一致才能更新commit，不然可能会有安全性问题导致已经commit的日志被覆盖，我忘了哪个测试一直过不了后来发现就是这个原因，所以论文一定要非常仔细读。\nfunc (rf *Raft) doReplicate(i int) { rf.rw.RLock() if rf.currentState != Leader { rf.rw.RUnlock() return } if rf.nextIndex[i] \u0026lt;= rf.getDummyLogntry().Index { args := rf.getDefaultInstallSnapshotArgs() rf.rw.RUnlock() reply := InstallSnapshotReply{} if rf.sendInstallSnapshot(i, \u0026amp;args, \u0026amp;reply) { rf.rw.Lock() rf.handleInstallSnapshotResponse(i, args, reply) rf.rw.Unlock() } } else { args := rf.getDefaultAppendEntriesArgs(i) rf.rw.RUnlock() reply := AppendEntriesReply{} if rf.sendAppendEntries(i, \u0026amp;args, \u0026amp;reply) { rf.rw.Lock() rf.handleAppendEntriesReponse(i, \u0026amp;args, \u0026amp;reply) rf.rw.Unlock() } } } 这里我参考了 LebronAI 的设计。\n如果为每一次Start、心跳都广播发送一次append entries，则将下层的日志同步与上层的提交新指令强绑定了，会造成RPC数量过多，还会重复发送很多次相同的日志项。每次发送 rpc 都不论是发送端还是接收端都需要若干次系统调用和内存拷贝，rpc 次数过多也会对 CPU 造成不必要的压力。\n这里可以做一个batching的优化，也将二者之间解耦。这里原作者参考了SOFAJraft的日志复制模型，让每个peer对于其他所有peer各维护一个replicator协程，负责在自己成为leader时对单独一个peer的日志复制。\n这个协程利用条件变量 sync.Cond 执行 Wait 来避免耗费 cpu，每次需要进行一次日志复制时调用 Signal 唤醒。它在满足复制条件时会尽最大努力将[nextIndex, lastIndex]之间的日志复制到peer上。\n由于leader使用replicator维护对于一个peer的日志复制，同一时间下最多只会发送一个RPC，若RPC丢失、超时很可能触发re-election。因此：\n 心跳计时器到期，很急，要立即发送RPC。leader commit更新时也要立即发送RPC，这个是为啥我忘记了。 Start被调用，不急，只需调用条件变量的 Singal，让replicator慢慢发。  func (rf *Raft) replicator(peer int) { rf.replicatorCond[peer].L.Lock() defer rf.replicatorCond[peer].L.Unlock() for !rf.Killed() { for !rf.needToReplicate(peer) { rf.replicatorCond[peer].Wait() } rf.doReplicate(peer) } } func (rf *Raft) needToReplicate(peer int) bool { rf.rw.RLock() defer rf.rw.RUnlock() return rf.currentState == Leader \u0026amp;\u0026amp; rf.nextIndex[peer] \u0026lt;= rf.getLastLogEntry().Index } func (rf *Raft) boardcastHeartbeat(isHeartbeat bool) { for index := range rf.peers { if index == rf.me { continue } if isHeartbeat { go rf.doReplicate(index) } else { rf.replicatorCond[index].Signal() } } rf.heartbeatTimer.Reset(StableHeartbeatTimeout()) } handler 完全按照论文图中伪代码实现，包括了课程视频中提到的加速解决日志冲突的优化。\nfunc (rf *Raft) AppendEntries(args *AppendEntriesArgs, reply *AppendEntriesReply) { rf.rw.Lock() DPrintf(\u0026#34;[Server %d][term %d lastindex %d lastterm %d commit %d] receive AppendEntries %+v from %d\u0026#34;, rf.me, rf.currentTerm, rf.getLastLogEntry().Index, rf.getLastLogEntry().Term, rf.commitIndex, args, args.LeaderId) defer rf.rw.Unlock() defer DPrintf(\u0026#34;[Server %d] reply [%s] for AppendEntries to %d\u0026#34;, rf.me, reply, args.LeaderId) needToPersist := false if args.Term \u0026lt; rf.currentTerm { reply.Success, reply.Term = false, rf.currentTerm return } if args.Term \u0026gt; rf.currentTerm { rf.currentTerm = args.Term needToPersist = true } rf.currentState = Follower rf.electionTimer.Reset(RandomizedElectionTimeout()) if args.PrevLogIndex \u0026lt; rf.getDummyLogntry().Index { reply.Success, reply.Term = false, 0 if needToPersist { rf.persist() } return } if !rf.isLogMatch(args.PrevLogIndex, args.PrevLogTerm) { reply.Term, reply.Success = rf.currentTerm, false reply.XIndex, reply.Term = rf.getConflictEntry(args.PrevLogIndex) if needToPersist { rf.persist() } return } lastLogIndex := rf.getLastLogEntry().Index for index, entry := range args.Entries { if entry.Index \u0026gt; lastLogIndex || rf.logs[rf.getSliceIndex(entry.Index)].Term != entry.Term { rf.logs = append(rf.logs[:rf.getSliceIndex(entry.Index)], args.Entries[index:]...) DPrintf(\u0026#34;[Server %d] append Follower\u0026#39;s last log index from %d to %d\u0026#34;, rf.me, lastLogIndex, rf.getLastLogEntry().Index) needToPersist = true break } } rf.maybeAdvanceFollowerCommit(args.LeaderCommit) reply.Success = true if needToPersist { rf.persist() } } persistence 论文中提到有三个变量是需要持久化的：currentTerm、votedFor、log[]，这三个量每次改变之后都应该持久化。\n持久化应当在被其他协程感知（发送RPC、释放锁）之前完成，而每个函数中如果没有改变这三个量（如加锁之后发现RPC过期）则不用持久化，若有也只需持久化一次，所以我在很多地方都使用了一个 needToPersist 布尔量进行判断。这样写感觉不够优雅，暂时没想到其他方法。\nlog-compaction 对于leader，在replicator中根据next index判断出需要给peer发送快照时，调用 persister.ReadSnapshot 获得快照并发送。\n对于接收方，需要判断如果 args.LastIncludedIndex \u0026lt;= rf.commitIndex，则拒绝接收快照。这说明本地状态机已经至少比该快照更新（或者将要，因为applier协程已经在apply这些日志的过程中了），可能导致raft回到旧的状态。应当等待service层调用 Snapshot 函数来安装快照。接收快照后，异步写入到applyCh中。\n对于两个service层给raft层安装快照的函数，它们的区别是：Snapshot 是由service层在处理apply message时判断raft state\u0026rsquo;s size是否达到阈值，主动调用。CondInstallSnapshot 是service层在处理apply message中leader发来的更新的快照时调用，也需要再次判断是否 LastIncludedIndex \u0026lt;= rf.commitIndex，安装快照之后应该更新lastApplied、commitIndex。\n安装快照后需要压缩日志，但是需要记录下包含在快照中的最新的日志项的index和term，我将其记录在dummy entry（即rf.log[0]）中。此外被删除的日志项需要被正确的删除使其能够被gc。\napplier 根据论文，一旦commitIndex \u0026gt; lastApplied，则需要将[lastApplied+1, commitIndex]中的所有日志项apply到状态机并增加lastApplied。\n一开始我的实现是每次commitIndex更新，都异步起一个协程将[lastApplied+1, commitIndex]间日志写入applyCh。但是因为写channel时不能持有锁，所以这个过程只能是：\n加锁 -\u0026gt; 深拷贝日志项 -\u0026gt; 释放锁 -\u0026gt; 写channel -\u0026gt; 加锁 -\u0026gt; 更新lastApplied -\u0026gt; 释放锁\n日志在push完之前不会更新lastApplied，这样容易造成相同的日志项被重复apply，存在资源浪费。所以这里也可以参考之前replicator的实现思路，后台起一个applier协程，平时调用一个条件变量的 Wait ，被 Signal 唤醒时将[lastApplied+1, commitIndex]中的所有日志项apply到状态机，每次更新commitIndex时调用 Signal。这样即能避免日志被重复apply，也完成了 apply 日志到状态机和 raft 提交新日志之间的解耦。\nfunc (rf *Raft) applier(applyCh chan ApplyMsg) { for !rf.Killed() { rf.rw.Lock() for !rf.needToApply() { rf.applierCond.Wait() } lastApplied, commitIndex := rf.lastApplied, rf.commitIndex needToApply := DeepCopy(rf.logs[rf.getSliceIndex(lastApplied+1) : rf.getSliceIndex(commitIndex)+1]) rf.rw.Unlock() for _, entry := range needToApply { applyMsg := ApplyMsg{ CommandValid: true, Command: entry.Command, CommandIndex: entry.Index, CommandTerm: entry.Term, RaftStateSize: rf.persister.RaftStateSize(), } applyCh \u0026lt;- applyMsg DPrintf(\u0026#34;[Server %d] applied log [index %d] at term %d\u0026#34;, rf.me, entry.Index, entry.Term) } rf.rw.Lock() if commitIndex \u0026gt; rf.lastApplied { rf.lastApplied = commitIndex } rf.rw.Unlock() } } 需要注意因为写channel时是不加锁的，而写channel是可能出现并发的，可能存在一种情况：applier在写入一批旧日志时，follower接受leader的 InstallSnapshot 之后将新的snapshot写入channel。此时channel的写入顺序可能是：旧日志1 -\u0026gt; 新快照 -\u0026gt; 旧日志2。\nservice层读channel是线性的，在读出snapshot并调用 CondInstallSnapshot 后会更新raft层的lastApplied、commitIndex。因此在raft层apply完日志之后，重新获得锁去更新lastApplied时要注意不能回退，在这二者之间可能service层已经对更新的快照调用过 CondInstallSnapshot 了（新快照的 lastIncludeIndex 一定大于 commitIndex ）。\n测试结果 2A Test (2A): initial election ... ... Passed -- 3.6 3 46 12142 0 Test (2A): election after network failure ... ... Passed -- 5.6 3 94 19292 0 Test (2A): multiple elections ... ... Passed -- 7.9 7 534 113432 0 PASS ok 6.824/raft\t17.177s 2B Test (2B): basic agreement ... ... Passed -- 1.1 3 16 4326 3 Test (2B): RPC byte count ... ... Passed -- 1.3 3 48 153910 11 Test (2B): agreement despite follower disconnection ... ... Passed -- 4.3 3 75 19840 7 Test (2B): no agreement if too many followers disconnect ... ... Passed -- 4.7 5 146 33983 4 Test (2B): concurrent Start()s ... ... Passed -- 1.5 3 18 5054 6 Test (2B): rejoin of partitioned leader ... ... Passed -- 5.1 3 117 27458 4 Test (2B): leader backs up quickly over incorrect follower logs ... ... Passed -- 9.8 5 1023 627193 102 Test (2B): RPC counts aren't too high ... ... Passed -- 3.0 3 42 12296 12 PASS ok 6.824/raft\t30.976s 2C Test (2C): basic persistence ... ... Passed -- 6.0 3 91 21819 6 Test (2C): more persistence ... ... Passed -- 18.3 5 821 178397 16 Test (2C): partitioned leader and one follower crash, leader restarts ... ... Passed -- 2.7 3 35 8235 4 Test (2C): Figure 8 ... ... Passed -- 27.9 5 530 117688 23 Test (2C): unreliable agreement ... ... Passed -- 3.0 5 753 240518 246 Test (2C): Figure 8 (unreliable) ... ... Passed -- 36.6 5 1684 3862021 145 Test (2C): churn ... ... Passed -- 16.5 5 7937 3098958 1199 Test (2C): unreliable churn ... ... Passed -- 16.3 5 1631 1031494 298 PASS ok 6.824/raft\t127.309s 2D Test (2D): snapshots basic ... ... Passed -- 2.4 3 247 96514 251 Test (2D): install snapshots (disconnect) ... ... Passed -- 46.7 3 1035 293753 399 Test (2D): install snapshots (disconnect+unreliable) ... ... Passed -- 52.4 3 1153 310385 377 Test (2D): install snapshots (crash) ... ... Passed -- 32.0 3 722 206681 322 Test (2D): install snapshots (unreliable+crash) ... ... Passed -- 43.7 3 806 220815 388 PASS ok 6.824/raft\t177.243s ","date":"2022-02-03T15:04:30+08:00","permalink":"https://ziannchen.work/2022/mit-6.824-lab2-raft/","title":"mit-6.824 lab2: Raft"},{"content":"Lab1: MapReduce 在本次lab中我们的任务是实现一个分布式的MapReduce，它由两个程序组成，Coordinator和Worker。只有一个Coordinator，一个或多个Worker并行执行。\n每个Worker将通过RPC与Coordinator通信以请求一个Map或Reduce任务，之后从一个或多个文件中读取任务的输入，执行任务，并将任务的输出写入一个或多个文件。\nCoordinator应注意到Worker是否在合理的时间内（10s）完成了任务，如果没有则将相同的任务交给另一个Worker。\nCoordinator 写这个lab的时候刚学go语言不久，觉得channel这个东西很帅，就使用了很多channel实现了一个lock-free版本的Coordinator，实践了一下csp。\n核心结构体 Coordinator维护每一个Map和Reduce任务的状态，这样就不用维护每一个worker的状态，这也利于worker的弹性伸缩。\nxxxidCh用于在获取任务编号并发放给worker，xxxDoneCh和xxxUndoneCh用于获取完成或未完成的任务编号修改任务状态。\ntype Coordinator struct { files []string nMap int nReduce int mapidCh chan int reduceidCh chan int mapStatus []Task reduceStatus []Task heartbeatCh chan heartbeatMsg reportCh chan reportMsg stateCh chan getStateMsg mapDoneCh chan Execution reduceDoneCh chan Execution mapUndoneCh chan Execution reduceUndoneCh chan Execution mapComplete bool reduceComplete bool mapRemain int reduceRemain int } 每个任务的状态有3种，每个任务被初始化时都是UnStarted，被分配给Worker之后转换为Processing，收到Report完成转为Done，未完成转为UnStarted。\n结构体Task用term和任务状态共同表示一个任务的信息，term代表该任务被分配给worker执行的次数。\ntype TaskStatus int const ( UnStarted TaskStatus = iota Processing Done ) type Task struct { term int TaskStatus } RPC-handler Coordinator接收到RPC之后，包装出一个xxxMsg结构，传入RPC对应的channel中。\nDone在这里作用类似于一个回调。Coordinator在启动时会在后台启动一个goroutine，不断监控 heartbeatCh 和 reportCh 中的Msg并处理，处理完成后执行msg.Done \u0026lt;- struct{}{}。在RPC handler中只需要等待Done这个channel返回。\ntype heartbeatMsg struct { response *HeartbeatResponse Done chan struct{} } type reportMsg struct { request *ReportRequest Done chan struct{} } func (c *Coordinator) Heartbeat(request *HeartbeatRequest, response *HeartbeatResponse) error { log.Println(\u0026#34;[Coordinator] receive a request from worker\u0026#34;) msg := heartbeatMsg{ response: response, Done: make(chan struct{}), } c.heartbeatCh \u0026lt;- msg \u0026lt;-msg.Done log.Printf(\u0026#34;[Coordinator] run heartbeat [%s] for worker\u0026#34;, response) return nil } func (c *Coordinator) Report(request *ReportRequest, response *ReportResponse) error { log.Printf(\u0026#34;[Coordinator] receive worker\u0026#39;s report [%s]\u0026#34;, request) msg := reportMsg{ request: request, Done: make(chan struct{}), } c.reportCh \u0026lt;- msg \u0026lt;-msg.Done log.Println(\u0026#34;[Coordinator] finish dealing with the report from worker\u0026#34;) return nil } handleHeartbeatMsg函数中处理心跳，根据当前Map和Reduce任务的状态给Worker分配一个任务、让worker等待或是告知所有任务已经完成。任务的id从mapidCh或reduceidCh两个channel中读出，在response中还要加上任务的term，每次分配该任务前需要对term自增以在不同的执行者之间区分。\n那么任务的id是什么时候写入channel中的呢？Coordinator在初始化时先将所有Map任务的id写入mapidCh，在所有Map任务都完成后将所有Reduce任务的id写入reduceidCh。\n需要注意一点，每个任务在分配之后10s内如果没有收到Report，则应该默认任务失败。这需要另起一个goroutine来判断，直接sleep 10s之后将id写入Undone channel即可，让run函数去判断。\n在handleReportMsg函数中处理worker的返回任务结果，根据结构类型将任务的Execution写入对应的Done/Undone channel。我将任务的term和id包装成一个Execution结构表示任务的一次执行，使得某次任务失败是超时还是worker返回失败这两种情况可以被区分。\ntype Execution struct { term int id int } 核心逻辑 run函数是Coordinator的核心，它作为一个后台运行的goroutine在不断的循环中监听各个channel并执行对应的操作。由于所有的数据都在这一个goroutine中修改，避免了data-race。\nCoordinator真正处理worker上报的任务的完成情况是由run函数在select中同时监听这4个channel，再根据任务id来执行对应逻辑。因此handleReportMsg函数可以另起一个goroutine来执行，这4个channel的容量也只需设置为1。\n从4个channel读出任务id后要注意，只有在对应的状态、Execution中term和本地任务的term一致时才能执行逻辑。\n例如某个MapFailed消息在10s之后到达，这可能是因为网络拥塞或是worker执行任务太慢，这个map任务已经被重新分配给了另一个worker，此时状态是仍是Processing。但这时term不一致应该放弃处理这个MapFailed消息。\nfunc (c *Coordinator) run() error { for { select { case hbMsg := \u0026lt;-c.heartbeatCh: c.handleHeartbeatMsg(hbMsg) case rpMsg := \u0026lt;-c.reportCh: go c.handleReportMsg(rpMsg) case e := \u0026lt;-c.mapDoneCh: if c.mapStatus[e.id].TaskStatus == Processing \u0026amp;\u0026amp; c.mapStatus[e.id].term == e.term { ··· } case e := \u0026lt;-c.reduceDoneCh: if c.reduceStatus[e.id].TaskStatus == Processing \u0026amp;\u0026amp; c.reduceStatus[e.id].term == e.term { ··· } case e := \u0026lt;-c.mapUndoneCh: if c.mapStatus[e.id].TaskStatus == Processing \u0026amp;\u0026amp; c.mapStatus[e.id].term == e.term { ··· } case e := \u0026lt;-c.reduceUndoneCh: if c.reduceStatus[e.id].TaskStatus == Processing \u0026amp;\u0026amp; c.reduceStatus[e.id].term == e.term { ··· } case stMsg := \u0026lt;-c.stateCh: stMsg.state \u0026lt;- c.reduceComplete } } } Worker worker的实现比较简单，只需要循环向coordinator请求任务执行。\nfunc Worker(mapf func(string, string) []KeyValue, reducef func(string, []string) string) { // Your worker implementation here. \tfor { response := doHeartbeat() log.Printf(\u0026#34;[Worker] receive coordinator\u0026#39;s heartbeat [%s]\u0026#34;, response) switch response.Type { case Map: doMapTask(mapf, response.Id, response.Term, response.NReduce, response.Name) case Reduce: doReduceTask(reducef, response.Id,response.Term, response.NMap) case Wait: time.Sleep(1 * time.Second) case Completed: return default: panic(fmt.Sprintf(\u0026#34;[Worker] unexpected jobType %v\u0026#34;, response.Type)) } } } 执行Map任务时，只需将mapf函数产生的中间文件kv pair按照ihash(kv.Key)%nReduce的余数写入不同的文件等待Reduce即可。写入的文件要先调用ioutil.TempFile(\u0026quot;\u0026quot;, \u0026ldquo;temp\u0026rdquo;)生成再调用os.Rename()改为mr-i-j。\n执行Reduce任务时，先建立一个kv数组，再将所有中间文件中的kv pair append到数组中再排序，将相同key对应的所有value append到一个string数组中，喂给reducef函数执行。看起来非常暴力，在工业界应该不可行，但通过本次lab的测试足够了。\n","date":"2022-02-03T15:01:24+08:00","permalink":"https://ziannchen.work/2022/mit-6.824-lab1-mapreduce/","title":"mit-6.824 lab1: MapReduce"},{"content":"前言 21年的3月份，大三下学期，我收到了一份暑期实习的offer。需要提前学习一下go语言，之后在某学长的安利下我了解到了mit-6.824这门课程，他建议我做一下这门课的4个lab就当实践一下go。不过我配好环境后就去浪了2333，也就断断续续的在b站上看了几期课的视频。\n真正开始写lab还是暑假实习在公司摸鱼的时候开始的，当时还拉着旁边组的一个实习生一起写相互交流进度。不得不说，课程、论文和lab真的都是非常非常的硬核（虽然我论文只大概看了前几篇），分布式系统这个领域也真的是非常非常的有趣，比学校里学的东西不知道高到哪里去了。暑假结束时还只写完了lab2，lab3只写了一点点，之后由于搞完秋招后一直在玩，年底又去写PingCAP talent-plan的tinykv了（这个也挺有意思的，也更贴近工业界，可惜文档给的太少，与之相比6.824的实现就像个玩具）导致进度很慢，最终22年1月中旬才全部写完。\n最近（毕业之前）我应该会将整理完所有的文档、实现思路发出来，也锻炼一下自己写技术文章的水平。\n一些资料 我的实验配置  win10 + wsl2 + ubuntu 20.04 16G内存 go version 1.15  课程网站 6.824 Schedule: Spring 2021\n用于并发测试的脚本 #!/bin/bash rm -rf tmp-$1 mkdir tmp-$1 start_time=$(date + %s) [ -e /tmp/fd1 ] || mkfifo /tmp/fd1 exec 3\u0026lt;\u0026gt;/tmp/fd1 rm -rf /tmp/fd1 # 同时执行 10 个线程，依照cpu核心数视情况而定 for ((i = 1; i \u0026lt;= 10; i++)); do echo \u0026gt;\u0026amp;3 done for ((i = 1; i \u0026lt;= 500; i++)); do read -u3 { touch ./tmp-$1/report_$i.log go test -run $1 -race \u0026gt; ./tmp-$1/report_$i.log s=$(tail -n 1 ./tmp-$1/report_$i.log) if [ ${s:0:2} == \u0026#39;ok\u0026#39; ] then rm ./tmp-$1/report_$i.log else echo \u0026#34;test $iFailed\u0026#34; fi echo \u0026gt;\u0026amp;3 } \u0026amp; done wait stop_time=$(date +%s) echo \u0026#34;TIME:$(expr $stop_time - $start_time)\u0026#34; exec 3\u0026lt;\u0026amp;- exec 3\u0026gt;\u0026amp;- ","date":"2022-02-03T14:01:24+08:00","permalink":"https://ziannchen.work/2022/mit-6.824-lab0-preface/","title":"mit-6.824 lab0: Preface"},{"content":"开端 一个程序员怎么能没有一个属于自己的技术博客呢？念叨这句话很久了，22年的春节我终于新建了文件夹。\n技术栈选型 框架 Hugo ，主题 Stack ，托管于 GitHub Pages，域名备案于阿里云。此外使用了 Github Actions 进行自动化部署。\n框架 一开始只知道博客可以托管在GitHub Pages上，作为完全不懂前端的我，肯定要选个简单的博客框架，上网查了下主要有Hexo和Hugo。\n Hexo？要用 nodejs，先pass。 Hugo？是 go 语言开发的，这我熟，就它了！  Hugo 是由 Go 语言实现的静态网站生成器。简单、易用、高效、易扩展、快速部署。Hugo 的速度真的非常快，本地运行后，更新一保存之后马上在浏览器之后就能看到结果。此外还要选个主题，我用的是 Stack。具体看 Hugo 官方文档 和 Stack 官方文档。\n折腾博客的各种小细节时，基本都在参考这位博主的 装修记录。\n需要注意一点，Hugo 框架的文件结构和 themes 中主题的文件结构是相同的，在修改样式时需要将主题文件夹中的同名文件复制到外边再做修改。若在主题文件夹中修改，由于自动化部署时是在 GitHub Actions 提供的 runner 上每次重新获取 hugo 和 theme 来生成静态网站，本地的更改就没了。\n写博客时，只需先执行\nhugo new post/xxx.md 之后修改顶部的 FrontMatter\n--- title: \u0026#34;my title\u0026#34; description: \u0026#34;my description\u0026#34; date: 2022-02-03T15:01:24+08:00 draft: true tags: - tag1 categories: - categorie1 --- 再之后就可以开始创作了。\n后端 将博客托管在Github Pages上，具体看 官网。\n新建一个public Repository，名字要是 username.github.io。之后在hugo框架根目录下执行 hugo -D 在 public 文件夹中生成静态网站，再将 public 文件夹中内容 push 到该 Repository 中即可完成部署。\n自动化部署 每次部署很麻烦，需要以下步骤：\nhugo -D cd public git add . git commit -m \u0026#34;some messages\u0026#34; git push 而且这样想要用git管理源文件有一点麻烦，自然想到使用 GitHub Actions 来完成自动化部署。\n需要先新建一个 Repository 保存博客框架源文件，我取名为 my-hugo-stack。username.github.io 这个Repository保存的是静态网站文件，不要混淆。\n在 my-hugo-stack 的 Actions 中，新建一个 workflow ，点击 configure 写入以下内容\nname: ci on: push: branches: - master jobs: build: runs-on: ubuntu-latest steps: - name: checkout uses: actions/checkout@v2.3.4 with: submodules: true - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: \u0026#39;0.92.1\u0026#39; extended: true - name: Build run: hugo -D - name: Add CNAME run: echo \u0026#34;ziannchen.work\u0026#34; \u0026gt; public/CNAME - name: Deploy uses: peaceiris/actions-gh-pages@v3 with: deploy_key: ${{ secrets.ACTIONS_DEPLOY_KEY }} external_repository: cza2000/cza2000.github.io publish_branch: master publish_dir: ./public commit_message: ${{ github.event.head_commit.message }} 此外还需要新建一对SSH密钥。私钥写入博客源文件仓库的 Settings - Actions secrets，命名为 ACTIONS_DEPLOY_KEY，公钥写入静态网站仓库的 Settings - Deploy keys，命名随意。\n之后将本地博客源文件 push 至 my-hugo-stack 的 master 分支就会触发 action，自动部署并将生成的 public 文件夹内的内容 push 到 username.github.io 中完成部署。\n由于我买了域名，这样做每次都把我的 CNAME 搞没了，我就在 yml 文件中手动加了一个 step，每次重新生成 CNAME 文件。\n为了更懒一点，又写了个脚本 deploy.sh:\n#!/bin/sh git add . msg=\u0026#34;rebuilding site $(date)\u0026#34; if [ -n \u0026#34;$*\u0026#34; ]; then msg=\u0026#34;$*\u0026#34; fi git commit -m \u0026#34;$msg\u0026#34; # Push source and build repos. git push TODO  考虑弄个 CDN 加了个访问量统计 不蒜子  ","date":"2022-01-31T14:38:17+08:00","permalink":"https://ziannchen.work/2022/hugostack-github-pages-github-actions-%E5%BB%BA%E7%AB%99%E8%AE%B0%E5%BD%95/","title":"Hugo\u0026Stack + Github Pages + Github Actions 建站记录"}]