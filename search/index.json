[{"content":"lab课程网址 https://pdos.csail.mit.edu/6.824/labs/lab-shard.html\n本次lab是最难的一次lab，很多地方需要我们自由发挥，不像lab2那样可以参考论文。\nLab2和Lab3构成基础分布式数据库的框架，实现了多节点间的数据一致性，支持crud，数据同步和快照保存。然而，由于所有的请求都需要由 leader 来处理，当数据增长到一定程度时，若仍然使用单一集群服务所有数据，leader面对的压力会非常大，请求响应时间也会延长，磁盘空间也会不足。在这种模式下，增加机器并不会带来性能的提升，反而存在浪费。一个非常直接的解决方法，就是将数据按照某种方式分开存储到不同的集群上，将不同的请求引流到不同的集群，降低单一集群的压力，提供更为高效、更为健壮的服务。\nLab4就是要实现数据的划分，将不同的数据划分到不同的集群上，保证相应数据请求引流到对应的集群。这里，将互不相交并且组成完整数据的每一个数据子集称为 Shard。在同一阶段中，Shard 与集群的对应关系称为 Config，随着时间的推移，增加或减少机器、某个 Shard 中的数据请求过热，Shard 需要在不同集群之中进行迁移。如何在 Config更新、 Shard 迁移的同时仍能正确对外提供强一致性的服务，是lab4主要挑战。\n一个集群只有Leader才能服务，系统的性能与集群的数量成正比。lab3是一个集群，lab4要实现的是多个集群之间的配合。\n我画了一个 ShardKV 最终的结构图\n 图片 1 \nShardCtrler Client 在向 Server 发送RPC之前，需要先知道目标 key 所在的 Shard 位于哪一个 Group，以及如何和这个 Group 中的leader通信。这就需要有一个地方保存 shard -\u0026gt; gid 和 gid -\u0026gt; server 信息，这就是lab4A中需要实现的 ShardCtrler，它使用 Config 结构保存这些信息。\n// A configuration -- an assignment of shards to groups. // Please don\u0026#39;t change this. type Config struct { Num int // config number \tShards [NShards]int // shard -\u0026gt; gid \tGroups map[int][]string // gid -\u0026gt; servers[] } 每次 shard -\u0026gt; gid 的对应关系被更改时，ShardCtrler 创建一个新的 Config 保存新的对应关系。ShardCtrler 支持Join、Leave、Move、Query 4种RPC来添加新的 Group、删除 Group，在 Group 之间移动 Shard 以及查询对应 Num 的 Config，底层也使用Raft协议在多台机器上进行数据同步。因此整体实现和lab3类似。\nClient 为了简化逻辑4种请求共用一个RPC，也需要加上 ClientID 和 RequestID 让 server 端能够去重。\ntype CommandRequest struct { ClientID int RequestID int OpType JoinArgs LeaveArgs MoveArgs QueryArgs } type CommandResponse struct { Err Err Config Config } type JoinArgs struct { Servers map[int][]string // new GID -\u0026gt; servers mappings } type LeaveArgs struct { GIDs []int } type MoveArgs struct { Shard int GID int } type QueryArgs struct { Num int // desired config number } Server 对于RPC的处理模型和lab3是一样的，由于Config数据较小，还不用处理快照。\nJoin Join 操作向当前配置中新增一些server，这些server可能被加入现有的 Group 中，也可能是新增的 Group。\n新增的 Group 还没有 Shard，需要在 Groups 中对 Shards 进行平衡并且要产生尽可能少的 Shard 迁移，平衡的方法是每次循环让拥有 Shard 最多的 Group 分一个给拥有 Shard 最少的 Group，直到它们之间的差值小等于1。\nShardCtrler 刚启动时还没有 Config 信息，第一次执行 Join 时所有的 Shard 还未被分配到具体的 Group 上，对应的 gid 是0，我称为 zombieShard。因此在处理 Join 时也要分配可能存在的 zombieShard。此外maps数据需要深拷贝。\nfunc (sc *ShardCtrler) executeJoin(servers map[int][]string) { length := len(sc.configs) lastConfig := sc.configs[length-1] newGroups := deepCopy(lastConfig.Groups) for gid, servers := range servers { newGroups[gid] = servers } newConfig := Config{ Num: length, Shards: [NShards]int{}, Groups: newGroups, } groupToShards := getGroupToShards(newGroups, lastConfig.Shards) zombieShards := []int{} for shard, gid := range lastConfig.Shards { if gid == 0 { zombieShards = append(zombieShards, shard) } } for _, shard := range zombieShards { target := getMinGroup(groupToShards) groupToShards[target] = append(groupToShards[target], shard) } groupToShards = balanceShardBetweenGroups(groupToShards) for gid, shards := range groupToShards { for _, shard := range shards { newConfig.Shards[shard] = gid } } sc.configs = append(sc.configs, newConfig) } Leave Group 被删除后，其原先拥有的 Shard 就成了 zombieShard，应当依次分配被拥有 Shard 数量最少的 Group。\nfunc (sc *ShardCtrler) executeLeave(GIDs []int) { length := len(sc.configs) lastConfig := sc.configs[length-1] newGroups := deepCopy(lastConfig.Groups) newConfig := Config{ Num: length, Shards: [NShards]int{}, Groups: newGroups, } groupToShards := getGroupToShards(newGroups, lastConfig.Shards) zombieShards := []int{} for _, gid := range GIDs { delete(newConfig.Groups, gid) if shards, ok := groupToShards[gid]; ok { zombieShards = append(zombieShards, shards...) delete(groupToShards, gid) } } for _, shard := range zombieShards { target := getMinGroup(groupToShards) groupToShards[target] = append(groupToShards[target], shard) } for gid, shards := range groupToShards { for _, shard := range shards { newConfig.Shards[shard] = gid } } sc.configs = append(sc.configs, newConfig) } Move 将指定的 Shard 交由新的 Group 负责，只需要改动 Shards 数组。\nfunc (sc *ShardCtrler) executeMove(shard int, gid int) { length := len(sc.configs) lastConfig := sc.configs[length-1] newGroups := deepCopy(lastConfig.Groups) newConfig := Config{ Num: length, Shards: lastConfig.Shards, Groups: newGroups, } newConfig.Shards[shard] = gid sc.configs = append(sc.configs, newConfig) } Query Query 查询指定版本的 Config。\nfunc (sc *ShardCtrler) executeQuery(num int) Config { length := len(sc.configs) config := Config{} if num == -1 || num \u0026gt;= length { config = sc.configs[length-1] } else { config = sc.configs[num] } newGroups := deepCopy(config.Groups) newConfig := Config{ Num: config.Num, Shards: config.Shards, Groups: newGroups, } return newConfig } 测试结果 Test: Basic leave/join ... ... Passed Test: Historical queries ... ... Passed Test: Move ... ... Passed Test: Concurrent leave/join ... ... Passed Test: Minimal transfers after joins ... ... Passed Test: Minimal transfers after leaves ... ... Passed Test: Multi-group join/leave ... ... Passed Test: Concurrent multi leave/join ... ... Passed Test: Minimal transfers after multijoins ... ... Passed Test: Minimal transfers after multileaves ... ... Passed Test: Check Same config on servers ... ... Passed PASS ok 6.824/shardctrler\t5.641s server 整体结构 ShardKV 的状态机 db 由多个 Shard 组成，每个 Shard 包含了自己的状态、kv和客户端请求去重表，这使得不同的 Shard 之间可以在独立迁移的同时不影响未受影响的 Shard 对外正常提供服务，也可以通过 Shard 的状态来进行许多判断，每个状态的含义在注释中。\ntype ShardKV struct { mu sync.RWMutex me int rf *raft.Raft applyCh chan raft.ApplyMsg make_end func(string) *labrpc.ClientEnd gid int ctrlers []*labrpc.ClientEnd maxraftstate int // snapshot if log grows this big  // Your definitions here. \tprevConfig shardctrler.Config currConfig shardctrler.Config persister *raft.Persister scClerk *shardctrler.Clerk notifyChans map[int]chan CommandResponse db map[int]*Shard lastAppliedIndex int } type ShardStatus int const ( // The group serves and owns the shard. \tServing ShardStatus = iota // The group serves the shard, but does not own the shard yet. \tPulling // The group does not serve and own the partition. \tInvalid // The group owns but does not serve the shard. \tErasing // The group own the shard and serve it, but it\u0026#39;s waiting for ex-owner to delete it \tWaiting ) type Shard struct { Status ShardStatus KV map[string]string LastSessions map[int]*Session } leader需要执行多个定时任务，需要在后台启动协程来循环判断状态、执行任务、睡眠。我抽象出了一个 daemon 函数来完成这些。\nfunc StartServer(servers []*labrpc.ClientEnd, me int, persister *raft.Persister, maxraftstate int, gid int, ctrlers []*labrpc.ClientEnd, make_end func(string) *labrpc.ClientEnd) *ShardKV { ··· // Your initialization code here.  // Use something like this to talk to the shardctrler: \t// kv.mck = shardctrler.MakeClerk(kv.ctrlers) \tkv.applyCh = make(chan raft.ApplyMsg) kv.rf = raft.Make(servers, me, persister, kv.applyCh) kv.scClerk = shardctrler.MakeClerk(kv.ctrlers) kv.mu = sync.RWMutex{} kv.notifyChans = make(map[int]chan CommandResponse) kv.db = make(map[int]*Shard) for i := 0; i \u0026lt; shardctrler.NShards; i++ { kv.db[i] = \u0026amp;Shard{ Status: Invalid, KV: make(map[string]string), LastSessions: make(map[int]*Session), } } kv.lastAppliedIndex = -1 kv.prevConfig = shardctrler.Config{} kv.currConfig = shardctrler.Config{} kv.applySnapshot(persister.ReadSnapshot()) go kv.applier() go kv.daemon(kv.fetchConfig) go kv.daemon(kv.pullData) go kv.daemon(kv.eraseData) go kv.daemon(kv.proposeEmpty) return kv } func (kv *ShardKV) daemon(action func()) { for !kv.killed() { if _, isLeader := kv.rf.GetState(); isLeader { action() } time.Sleep(50 * time.Millisecond) } } applier 的结构和lab3类似，日志被 commit 之后根据 CommandType 的不同执行不同的applyxxx，其中 EraseData 和 ClientRequest 需要返回 response。\ntype CommandType int const ( ClientRequest CommandType = iota ConfChange InsertData EraseData StopWaiting Empty ) type RaftLogCommand struct { CommandType Data interface{} } func newRaftLogCommand(commandType CommandType, data interface{}) RaftLogCommand { return RaftLogCommand{ CommandType: commandType, Data: data, } } func (kv *ShardKV) applier() { for !kv.killed() { select { case applyMsg := \u0026lt;-kv.applyCh: if applyMsg.CommandValid { command := applyMsg.Command.(RaftLogCommand) kv.mu.Lock() if applyMsg.CommandIndex \u0026lt;= kv.lastAppliedIndex { DPrintf(\u0026#34;[Group %d][Server %d] discard out-of-date apply Msg [index %d]\u0026#34;, kv.gid, kv.me, applyMsg.CommandIndex) kv.mu.Unlock() continue } kv.lastAppliedIndex = applyMsg.CommandIndex response := \u0026amp;CommandResponse{} switch command.CommandType { case Empty: DPrintf(\u0026#34;[Group %d][Server %d] get empty in apply Msg [index %d]\u0026#34;, kv.gid, kv.me, applyMsg.CommandIndex) case ConfChange: lastestConf := command.Data.(shardctrler.Config) kv.applyConfChange(lastestConf, applyMsg.CommandIndex) case InsertData: resp := command.Data.(PullDataResponse) kv.applyInsertData(resp, applyMsg.CommandIndex) case StopWaiting: req := command.Data.(EraseDataRequest) kv.applyStopWaiting(req, applyMsg.CommandIndex) case EraseData: req := command.Data.(EraseDataRequest) response = kv.applyEraseData(req, applyMsg.CommandIndex) if currentTerm, isLeader := kv.rf.GetState(); currentTerm == applyMsg.CommandTerm \u0026amp;\u0026amp; isLeader { ch := kv.getNotifyChan(applyMsg.CommandIndex) ch \u0026lt;- *response } case ClientRequest: request := command.Data.(CommandRequest) response = kv.applyClientRequest(\u0026amp;request, applyMsg.CommandIndex) if currentTerm, isLeader := kv.rf.GetState(); currentTerm == applyMsg.CommandTerm \u0026amp;\u0026amp; isLeader { ch := kv.getNotifyChan(applyMsg.CommandIndex) ch \u0026lt;- *response } } if kv.needToSnapshot(applyMsg.RaftStateSize) { DPrintf(\u0026#34;[Group %d][Server %d] take a snapshot till [index %d]\u0026#34;, kv.gid, kv.me, applyMsg.CommandIndex) kv.takeSnapshot(applyMsg.CommandIndex) } kv.mu.Unlock() } else { kv.mu.Lock() DPrintf(\u0026#34;[Group %d][Server %d] received a snapshot from raft layer [index %d]\u0026#34;, kv.gid, kv.me, applyMsg.SnapshotIndex) if kv.rf.CondInstallSnapshot(applyMsg.SnapshotTerm, applyMsg.SnapshotIndex, applyMsg.Snapshot) { kv.applySnapshot(applyMsg.Snapshot) kv.lastAppliedIndex = applyMsg.SnapshotIndex } kv.mu.Unlock() } } } } 客户端请求 这里和lab3基本一样，不同的是handle RPC 以及日志apply时都需要额外判断在当前版本的 Config 下本 Group 是否负责该 key 所属的 Shard。\nfunc (kv *ShardKV) isShardMatch(shardId int) bool { return kv.currConfig.Shards[shardId] == kv.gid \u0026amp;\u0026amp; (kv.db[shardId].Status == Serving || kv.db[shardId].Status == Waiting) } 配置更新 每个 Group 中的 leader 需要在后台启动一个协程向 ShardCtrler 定时使用 Query 拉取最新配置，一旦拉取到就需要提交一条 raft 日志，以在每台机器上更新配置。\n此外，每次只能拉取高一个版本的配置，而且为了防止集群的分片状态被覆盖，从而使得某些任务永远不会被执行，只有在每一 Shard 的状态都为 Serving 或 Invalid 时才能拉取、更新配置。\nfunc (kv *ShardKV) fetchConfig() { canFetchConf := true kv.mu.RLock() currConfNum := kv.currConfig.Num for shardId, shard := range kv.db { if shard.Status != Serving \u0026amp;\u0026amp; shard.Status != Invalid { canFetchConf = false break } } kv.mu.RUnlock() if canFetchConf { latestConfig := kv.scClerk.Query(currConfNum + 1) if latestConfig.Num == currConfNum+1 { kv.rf.Start(newRaftLogCommand(ConfChange, latestConfig)) } } } 在每台机器上，新配置对应的 raft 日志被 commit 之后，都需要更新本地的 prevConfig 和 currConfig，以及更新 db 中对应的 Shard 状态，以便让数据拉取、数据清理协程能检测到去进行数据迁移。\n在新版本的 Config 中新增的 Shard 状态改为 Pulling，等待拉取数据协程去其他 Group 上拉数据。失去的 Shard 状态改为 Erasing，等待其他 Group 来拉取数据。\nfunc (kv *ShardKV) applyConfChange(conf shardctrler.Config, index int) { if conf.Num != kv.currConfig.Num+1 { DPrintf(\u0026#34;[Group %d][Server %d] discard out-of-date conf change in apply Msg [index %d]\u0026#34;, kv.gid, kv.me, index) } else { kv.prevConfig = kv.currConfig kv.currConfig = conf for shardID, gid := range kv.currConfig.Shards { if gid != kv.gid { kv.db[shardID].Status = Invalid } else { kv.db[shardID].Status = Serving } } if kv.prevConfig.Num != 0 { for i, shard := range kv.db { if kv.prevConfig.Shards[i] != kv.gid \u0026amp;\u0026amp; kv.currConfig.Shards[i] == kv.gid { shard.Status = Pulling } if kv.prevConfig.Shards[i] == kv.gid \u0026amp;\u0026amp; kv.currConfig.Shards[i] != kv.gid { shard.Status = Erasing } } } DPrintf(\u0026#34;[Group %d][Server %d] apply latest config [ver %d shards %+v] in apply Msg [index %d]\u0026#34;, kv.gid, kv.me, conf.Num, conf.Shards, index) } } 数据拉取 新的 Config 在 applier 协程中被应用并不表示所属分片可以立刻对外提供服务，还需要等待在上一个版本的 Config 中不属于自身的 Shard 从它之前所属的 Group 中迁移到本 Group。\n这里显然不能在配置更新时同步阻塞的去拉取 Shard，这会阻塞 applier 协程，严重影响对外服务的可用性。那么是否可以异步的去拉取数据并提交日志？其实不行，leader 可能会在 apply 新配置之后到新数据被异步拉取到并提交日志之前宕机，而 follower 虽然会 apply 配置但是不会去拉数据，这样这些数据将永远无法被更新。\n因此，我们不能在 apply 配置的时候启动异步任务，而是应该只更新 shard 的状态，由单独的后台协程去检测每个 Shard 的状态，从而判断是否需要并执行分片迁移，分片清理等任务。为了让单独的协程能知道该向哪个 Group 去拉取数据或让它去删除数据，ShardKV 需要维护 currConfig 和 prevConfig，这样其他协程能够通过它们来得知所有 Shard 的 ex-owner。\n需要定义新的RPC来完成数据拉取。\ntype PullDataRequest struct { ConfNum int ShardIds []int } type PullDataResponse struct { Err Err ConfNum int Shards map[int]*Shard } 并行向状态为 Pulling 的不同 Shard 的 ex-owner 发送RPC来拉取数据，使用 waitGroup 来保证尝试拉取了一遍当前版本的配置所需要的所有 Shard 之后才能进行下一轮循环。\nfunc (kv *ShardKV) pullData() { kv.mu.RLock() groupToShards := kv.getGroupToShards(Pulling) currConfNum := kv.currConfig.Num wg := sync.WaitGroup{} for gid, shards := range groupToShards { wg.Add(1) servers := kv.prevConfig.Groups[gid] go func(servers []string, shards []int, confNum int) { defer wg.Done() for _, server := range servers { shardOwner := kv.make_end(server) args := PullDataRequest{ ConfNum: confNum, ShardIds: shards, } reply := PullDataResponse{} if shardOwner.Call(\u0026#34;ShardKV.PullData\u0026#34;, \u0026amp;args, \u0026amp;reply) \u0026amp;\u0026amp; reply.Err == OK { kv.rf.Start(newRaftLogCommand(InsertData, resp)) break } } }(servers, shards, currConfNum) } kv.mu.RUnlock() wg.Wait() } 只有在 PullDataRequest 中的配置版本与自身的配置版本相同时，才回应其需要的 Shard 信息。需要注意正确的对所有 Shard 深拷贝。\nfunc (kv *ShardKV) PullData(args *PullDataRequest, reply *PullDataResponse) { defer DPrintf(\u0026#34;[Group %d][Server %d] reply %s for PULL DATA request %s\u0026#34;, kv.gid, kv.me, reply, args) DPrintf(\u0026#34;[Group %d][Server %d] received a PULL DATA request %s\u0026#34;, kv.gid, kv.me, args) if _, isLeader := kv.rf.GetState(); !isLeader { reply.Err = ErrWrongLeader return } kv.mu.RLock() defer kv.mu.RUnlock() if kv.currConfig.Num \u0026lt; args.ConfNum { reply.Err = ErrNotReady return } if kv.currConfig.Num \u0026gt; args.ConfNum { panic(\u0026#34;duplicated pull data request\u0026#34;) } replyShards := make(map[int]*Shard) for _, shardId := range args.ShardIds { shard := kv.db[shardId] replyShards[shardId] = deepCopyShard(shard) } reply.ConfNum = kv.currConfig.Num reply.Shards = replyShards reply.Err = OK } 为了保证集群数据变更的幂等性，apply 时也要保证 Config 的版本与当前版本相同以及其 Shard 的本地状态为 Pulling，将其状态改为 Waiting 让数据清理协程去检测。\nfunc (kv *ShardKV) applyInsertData(resp PullDataResponse, index int) { if resp.ConfNum == kv.currConfig.Num { for shardID, shard := range resp.Shards { if kv.db[shardID].Status == Pulling { DPrintf(\u0026#34;[Group %d][Server %d] start to serve shard %d\u0026#34;, kv.gid, kv.me, shardID) kv.db[shardID] = deepCopyShard(shard) kv.db[shardID].Status = Waiting } else { DPrintf(\u0026#34;[Group %d][Server %d] encounter duplicated insert data [shardID %d status %s] in apply Msg [index %d]\u0026#34;, kv.gid, kv.me, shardID, ShardStatusName[shard.Status], index) return } } DPrintf(\u0026#34;[Group %d][Server %d] apply insert data in apply Msg [index %d]\u0026#34;, kv.gid, kv.me, index) } else { DPrintf(\u0026#34;[Group %d][Server %d] discard out-of-date insert data in apply Msg [index %d]\u0026#34;, kv.gid, kv.me, index) } } 数据清理 current owner 在完成数据拉取之后，需要清理掉每个新拉到的 Shard 对应的 ex-owner 机器上的旧数据。后台协程检查所有状态为 Waiting 的 Shard，并行向它们的 ex-owners 分别发送 RPC，告知它们：我已拉取到我要的数据，现在你可以把它们删了。这里 waitGroup 的用法同上。\nRPC返回且得知 ex-owners 上的数据清理已经完成后需要提交一条 StopWaiting 类型的 raft 日志，将这个信息同步到 Group 内所有机器上。\ntype EraseDataRequest struct { ConfNum int ShardIDs []int } type EraseDataResponse struct { Err Err } func (kv *ShardKV) eraseData() { kv.mu.RLock() groupToShards := kv.getGroupToShards(Waiting) currConfNum := kv.currConfig.Num wg := sync.WaitGroup{} for gid, shards := range groupToShards { wg.Add(1) servers := kv.prevConfig.Groups[gid] go func(servers []string, shards []int, confNum int) { defer wg.Done() for _, server := range servers { shardOwner := kv.make_end(server) args := EraseDataRequest{ ConfNum: confNum, ShardIDs: shards, } reply := EraseDataResponse{} if shardOwner.Call(\u0026#34;ShardKV.EraseData\u0026#34;, \u0026amp;args, \u0026amp;reply) \u0026amp;\u0026amp; reply.Err == OK { kv.rf.Start(newRaftLogCommand(StopWaiting, req)) break } } }(servers, shards, currConfNum) } kv.mu.RUnlock() wg.Wait() } StopWaiting 日志以及 Shard 的 Waiting 状态存在的意义是能够标记我是否已经成功在 ex-owner 上删除过期的 Shard。apply 时将对应的状态为 Waiting 的 Shard 更新状态为 Serving。\nfunc (kv *ShardKV) applyStopWaiting(req EraseDataRequest, index int) { if req.ConfNum == kv.currConfig.Num { for _, shardID := range req.ShardIDs { if kv.db[shardID].Status == Waiting { kv.db[shardID].Status = Serving DPrintf(\u0026#34;[Group %d][Server %d] erase shard %d on its ex-owner\u0026#34;, kv.gid, kv.me, shardID) } else { DPrintf(\u0026#34;[Group %d][Server %d] encounter duplicated stop waiting in apply Msg [index %d]\u0026#34;, kv.gid, kv.me, index) break } } DPrintf(\u0026#34;[Group %d][Server %d] apply stop waiting in apply Msg [index %d]\u0026#34;, kv.gid, kv.me, index) } else { DPrintf(\u0026#34;[Group %d][Server %d] discard out-of-date stop waiting in apply Msg [index %d]\u0026#34;, kv.gid, kv.me, index) } } ex-owner ex-owner 在处理 EraseData 的RPC时，需要返回数据清理是否完成，这里的处理类似处理客户端请求。\nfunc (kv *ShardKV) EraseData(req *EraseDataRequest, resp *EraseDataResponse) { defer DPrintf(\u0026#34;[Group %d][Server %d] resp %s for ERASE DATA request %s\u0026#34;, kv.gid, kv.me, resp, req) DPrintf(\u0026#34;[Group %d][Server %d] received a ERASE DATA request %s\u0026#34;, kv.gid, kv.me, req) index, _, isLeader := kv.rf.Start(newRaftLogCommand(EraseData, *req)) if !isLeader { resp.Err = ErrWrongLeader return } kv.mu.Lock() ch := kv.getNotifyChan(index) kv.mu.Unlock() select { case response := \u0026lt;-ch: resp.Err = response.Err case \u0026lt;-time.NewTimer(500 * time.Millisecond).C: resp.Err = ErrTimeout } go func() { kv.mu.Lock() kv.removeNotifyChan(index) kv.mu.Unlock() }() } apply 时将对应的状态为 Erasing 的 Shard 更新为 Invalid，清空 kv 和客户端请求去重表。\nfunc (kv *ShardKV) applyEraseData(req EraseDataRequest, index int) *CommandResponse { if req.ConfNum == kv.currConfig.Num { for _, shardID := range req.ShardIDs { if kv.db[shardID].Status == Erasing { kv.db[shardID] = \u0026amp;Shard{ Status: Invalid, } DPrintf(\u0026#34;[Group %d][Server %d] erase data [shardID %d] for config [ver %d] in apply Msg [index %d]\u0026#34;, kv.gid, kv.me, shardID, kv.currConfig.Num, index) } else { DPrintf(\u0026#34;[Group %d][Server %d] encounter duplicated erase data in apply Msg [index %d]\u0026#34;, kv.gid, kv.me, index) return \u0026amp;CommandResponse{OK, \u0026#34;\u0026#34;} } } return \u0026amp;CommandResponse{OK, \u0026#34;\u0026#34;} } else if req.ConfNum \u0026gt; kv.currConfig.Num { DPrintf(\u0026#34;[Group %d][Server %d] current config [ver %d], not ready for erase data request [ver %d] in apply Msg [index %d]\u0026#34;, kv.gid, kv.me, kv.currConfig.Num, req.ConfNum, index) return \u0026amp;CommandResponse{ErrNotReady, \u0026#34;\u0026#34;} } else { DPrintf(\u0026#34;[Group %d][Server %d] discard out-of-date erase data in apply Msg [index %d]\u0026#34;, kv.gid, kv.me, index) return \u0026amp;CommandResponse{OK, \u0026#34;\u0026#34;} } } 提交空日志 在某个涉及重启的测试中，有时候会出现集群对外出现活锁，无法再服务请求直到超时。我重新打了很多日志，发现这时各个 Group 间的 Config 版本不一致，且版本较低的 Group 的一些 Shard 状态不为 Serving 和 Invalid，这卡着配置更新协程无法拉取最新的 Config。按理说 Config 的版本只能以1为公差递增，其余的 Group 版本高说明也经历过较低的这个版本，应该有向这个 Group 发送过拉取数据和清理数据的RPC来更新 Shard 状态，那么为什么状态并没有被更新呢？\n仔细读了很久日志，我发现版本较低的 Group 在推进 Config 到这个版本之后已经正确处理过拉取数据或是清理数据的RPC也更新了 Shard 状态，但在重启后这最后处理的关键RPC对应的日志并没有重新被commit。原来，此时 leader 的 currentTerm 高于这个RPC对应的日志的 term，且这个时间节点客户端碰巧没有向该 Group 组执行读写请求，导致 leader 无法拥有当前任期的 term 的日志，无法将状态机更新到最新。\nlab4的最后一部分是我在写完 TinyKV 之后做的，我想到 TinyKV （其实 etcd 也是这么做的）中要求的 leader 在当选时要先提交一条空日志，这样可以保证集群的可用性，于是我也移植了这个特性到 6.824 中。\n想起了以前几个月前看过的 谭新宇 的文章，我知道了不能把这个特性加到 raft 层。于是我也让 leader 在 kv 层周期性的去检测下层是否包含当前 term 的日志，如果没有便 append 一条空日志，这样即可保证新选出的 leader 状态机能够迅速达到最新。\nfunc (kv *ShardKV) proposeEmpty() { if !kv.rf.HasLogAtCurrentTerm() { kv.rf.Start(newRaftLogCommand(Empty, nil)) } } 测试结果 Test: static shards ... ... Passed Test: join then leave ... ... Passed Test: snapshots, join, and leave ... ... Passed Test: servers miss configuration changes... ... Passed Test: concurrent puts and configuration changes... ... Passed Test: more concurrent puts and configuration changes... ... Passed Test: concurrent configuration change and restart... ... Passed Test: unreliable 1... ... Passed Test: unreliable 2... ... Passed Test: unreliable 3... ... Passed Test: shard deletion (challenge 1) ... ... Passed Test: unaffected shard access (challenge 2) ... ... Passed Test: partial migration shard access (challenge 2) ... ... Passed PASS ok 6.824/shardkv\t108.040s ","date":"2022-02-04T13:21:03+08:00","permalink":"https://cza2000.github.io/2022/mit-6.824-lab3-shardkv/","title":"mit-6.824 lab3: ShardKV"},{"content":"Lab3: KVRaft lab链接 https://pdos.csail.mit.edu/6.824/labs/lab-kvraft.html\n本次lab中我们需要使用lab2中实现的Raft库来构建一个可容错的 Key/Value 存储服务，要求其对外提供强一致性（Strong consistency）。\n这个KV存储服务支持Get/Put/Append三种客户端操作。客户端通过RPC与集群中的leader通信，leader接收到请求后将其包装在一条Raft日志中下放到Raft层进行共识，日志被apply后返回客户端结果。\n一些思考 在PartA的描述中提到，leader在将一个请求下放到raft层之后，commit之前宕机，这时它无法回复Clerk。又或者是，这条日志成功commit，但返回的RPC丢失。Clerk在规定时间内没有收到结果，会向另一台主机（可能是新选出的leader）发送RPC，这条日志最终被commit之后又会被应用于状态机，从而状态机执行了两次相同的请求。\n这要求我们能够判断重复的请求。因此每个请求都需要被唯一标识，请求中需要加上（ClientID, RequestID），Clerk每次请求成功之后自增RequestID。\n我们还需要在遇到重复的请求时直接返回第一次请求时的结果，这需要我们保存每一个Clerk的最后一次请求的结果ClientID -\u0026gt; (RequestID, LastResponse)。只需要保存最后一次请求结果是因为如果服务端收到RequestID = x的RPC，说明这个Clerk已经收到了RequestID为[1, x-1]之间内的所有请求的结果，服务端如果再次收到这个RequestID在区间之内的请求说明该RPC过期，直接丢弃即可。\nclient 我将3种请求共用了一个RPC，简化了逻辑。\nClerk保存一个leaderID，请求失败了再换另一个server，请求成功了自增requestID。\ntype Clerk struct { servers []*labrpc.ClientEnd // You will have to modify this struct. \tleaderID int clientID int64 requestID int } func (ck *Clerk) Get(key string) string { return ck.Command(key, \u0026#34;\u0026#34;, OpGet) } func (ck *Clerk) Put(key string, value string) { ck.Command(key, value, OpPut) } func (ck *Clerk) Append(key string, value string) { ck.Command(key, value, OpAppend) } func (ck *Clerk) Command(key, value string, op Operation) string { req := getCommandRequest(key, value, op, int(ck.clientID), ck.requestID)\tfor { resp := CommandResponse{} if !ck.servers[ck.leaderID].Call(\u0026#34;KVServer.Command\u0026#34;, \u0026amp;req, \u0026amp;resp) || resp.Err == ErrWrongLeader || resp.Err == ErrTimeout {\tck.leaderID = (ck.leaderID + 1) % len(ck.servers) continue } ck.requestID++ return\tresp.Value\t} } server KVServer的结构体如下：\ntype KVServer struct { mu sync.RWMutex me int rf *raft.Raft applyCh chan raft.ApplyMsg dead int32 // set by Kill()  maxraftstate int // snapshot if log grows this big  // Your definitions here. \tpersister *raft.Persister notifyChans map[int]chan *CommandResponse db map[string]string lastSessions map[int]Session lastAppliedIndex int } state-machine 本次lab中只需使用一个内存版本的 KV 状态机 map[string]string。\nRPC handler 客户端请求来临时，Server端会启动一个协程作为RPC handler来处理客户端请求，其中会调用 Raft.Start 函数将请求下放到Raft层形成一条日志去做共识。在Raft层，每条被commit的日志会按照index的顺序写入applyCh中，上层必须也按index序从applyCh中读出日志并应用于状态机，这样才能保证不同节点上的数据一致。\n这要求必须有一个单独的applier协程来循环读applyCh，并应用于状态机。由于来自不同客户端的请求是并发的，如果在RPC handler协程中直接读applyCh无法保证index序。返回给客户端的response要根据日志应用于状态机的结果来生成，这需要我们处理RPC handler和applier协程之间的通信问题。\n自然想到使用channel来通信，使用一个 notifyChans map (log index -\u0026gt; response) 来记录每一个请求对应的channel。在RPC handler协程将日志下放到Raft层之后，在notifyChans中注册一个channel并阻塞读，applier协程读出日志，应用于状态机之后生成response写入这个channel。RPC handler协程在规定时间内读出结果则正常返回客户端，若超时则返回超时。\nfunc (kv *KVServer) Command(req *CommandRequest, resp *CommandResponse) { // Your code here. \tkv.mu.RLock() defer DPrintf(\u0026#34;[KVServer %d] reply %+v for Request %+v\u0026#34;, kv.me, resp, req) DPrintf(\u0026#34;[KVServer %d] received Request %+v from Clerk\u0026#34;, kv.me, req) if req.Op != OpGet \u0026amp;\u0026amp; kv.isDuplicatedRequest(req.ClientID, req.RequestID) { resp.Err = kv.lastSessions[req.ClientID].Err kv.mu.RUnlock() return } kv.mu.RUnlock() index, _, isLeader := kv.rf.Start(*req) if !isLeader { resp.Err = ErrWrongLeader return } DPrintf(\u0026#34;[KVServer %d] add command into raft layer [index %d]\u0026#34;, kv.me, index) kv.mu.Lock() ch := kv.getNotifyChan(index) kv.mu.Unlock() select { case result := \u0026lt;-ch: resp.Value = result.Value resp.Err = result.Err case \u0026lt;-time.NewTimer(500 * time.Millisecond).C: resp.Err = ErrTimeout } go func() { kv.mu.Lock() kv.removeNotifyChan(index) kv.mu.Unlock() }() } func (kv *KVServer) applier() { for !kv.killed() { select { case applyMsg := \u0026lt;-kv.applyCh: if applyMsg.CommandValid { command := applyMsg.Command.(CommandRequest) kv.mu.Lock() if applyMsg.CommandIndex \u0026lt;= kv.lastAppliedIndex { DPrintf(\u0026#34;[KVServer %d] discard out-of-date apply Msg in [index %d]\u0026#34;, kv.me, applyMsg.CommandIndex) kv.mu.Unlock() continue } kv.lastAppliedIndex = applyMsg.CommandIndex var response *CommandResponse if command.Op != OpGet \u0026amp;\u0026amp; kv.isDuplicatedRequest(command.ClientID, command.RequestID) { DPrintf(\u0026#34;[KVServer %d] received a duplicated command in [index %d]\u0026#34;, kv.me, applyMsg.CommandIndex) response = kv.lastSessions[command.ClientID].CommandResponse } else { response = kv.applyCommand(command) if command.Op != OpGet { kv.lastSessions[command.ClientID] = Session{ RequestID: command.RequestID, CommandResponse: response, } } } if kv.needToSnapshot(applyMsg.RaftStateSize) { DPrintf(\u0026#34;[KVServer %d] reach maxraftstate, take a snapshot till [index %d]\u0026#34;, kv.me, applyMsg.CommandIndex) kv.takeSnapshot(applyMsg.CommandIndex) } if currentTerm, isLeader := kv.rf.GetState(); currentTerm == applyMsg.CommandTerm \u0026amp;\u0026amp; isLeader { ch := kv.getNotifyChan(applyMsg.CommandIndex) ch \u0026lt;- response } kv.mu.Unlock() } else { kv.mu.Lock() DPrintf(\u0026#34;[KVServer %d] received a snapshot from raft layer [index %d, term %d]\u0026#34;, kv.me, applyMsg.SnapshotIndex, applyMsg.SnapshotTerm) if kv.rf.CondInstallSnapshot(applyMsg.SnapshotTerm, applyMsg.SnapshotIndex, applyMsg.Snapshot) { kv.applySnapshotToService(applyMsg.Snapshot) kv.lastAppliedIndex = applyMsg.SnapshotIndex } kv.mu.Unlock() } } } } 有几点需要注意：\n  apply日志时需要防止状态机回滚。在lab2中提到作为follower的节点可能收到leader的install snapshot，将snapshot写入applyCh中，此时读applyCh的顺序是：旧日志1 -\u0026gt; 新快照 -\u0026gt; 旧日志2。应用了新快照之后要避免再次应用旧日志，所以应用快照之后也要更新 lastAppliedIndex，应用日志时要先判断是否 applyMsg.CommandIndex \u0026lt;= kv.lastAppliedIndex。\n  仅对leader的notifyChan进行通知。每个节点在读出日志后都要提交到状态机，且更新lastSessions。但只有leader需要将response写入notifyChan。leader可能会在提交日志后失去leader身份，所以在applier中写入response前要先判断。此时RPC handler协程就让其超时。\n  客户端的非读请求需要两次去重。重复的请求到来时，之前相同的请求可能已经被应用于该节点的状态机，也可能其对应的日志还没被commit。因此需要在RPC handler中调用Start之前以及日志commit之后应用于状态机之前两次去重。\n  leader在调用Start提交日志后去获取notifyChan来阻塞读 以及 applier 在commit日志并应用于状态机之后获取notifyChan来写入response 这二者之间顺序无法保证。因此channel容量设置为1，先获取channel的协程要负责创建channel，这个过程要加写锁。\n  func (kv *KVServer) getNotifyChan(index int) chan *CommandResponse { ch, ok := kv.notifyChans[index] if !ok { ch := make(chan *CommandResponse, 1) kv.notifyChans[index] = ch return ch } return ch } snapshot part B中要求我们在raft state size达到阈值时给raft层下发快照。快照中不仅需要包含KV状态机，还需要包含lastSessions客户端请求去重表。由于快照是和lastIncludeIndex对应的，所以需要由applier协程在将对应的index的日志应用于状态机后继续阻塞的生成快照。\n测试结果 3A Test: one client (3A) ... ... Passed -- 15.1 5 9881 941 Test: ops complete fast enough (3A) ... ... Passed -- 15.5 3 7032 0 Test: many clients (3A) ... ... Passed -- 15.6 5 11160 1171 Test: unreliable net, many clients (3A) ... ... Passed -- 16.2 5 7462 901 Test: concurrent append to same key, unreliable (3A) ... ... Passed -- 1.5 3 282 52 Test: progress in majority (3A) ... ... Passed -- 1.1 5 108 2 Test: no progress in minority (3A) ... ... Passed -- 1.0 5 184 3 Test: completion after heal (3A) ... ... Passed -- 1.0 5 63 3 Test: partitions, one client (3A) ... ... Passed -- 22.5 5 9323 643 Test: partitions, many clients (3A) ... ... Passed -- 23.3 5 18230 837 Test: restarts, one client (3A) ... ... Passed -- 22.0 5 12689 822 Test: restarts, many clients (3A) ... ... Passed -- 22.9 5 24109 1144 Test: unreliable net, restarts, many clients (3A) ... ... Passed -- 25.7 5 9398 873 Test: restarts, partitions, many clients (3A) ... ... Passed -- 30.3 5 19984 848 Test: unreliable net, restarts, partitions, many clients (3A) ... ... Passed -- 29.9 5 7443 622 Test: unreliable net, restarts, partitions, random keys, many clients (3A) ... ... Passed -- 32.9 7 14185 904 PASS ok 6.824/kvraft\t277.625s 3B Test: InstallSnapshot RPC (3B) ... ... Passed -- 3.4 3 2151 63 Test: snapshot size is reasonable (3B) ... ... Passed -- 2.8 3 5727 800 Test: ops complete fast enough (3B) ... ... Passed -- 3.2 3 6962 0 Test: restarts, snapshots, one client (3B) ... ... Passed -- 21.2 5 46519 4431 Test: restarts, snapshots, many clients (3B) ... ... Passed -- 21.6 5 53053 4531 Test: unreliable net, snapshots, many clients (3B) ... ... Passed -- 15.9 5 11057 1341 Test: unreliable net, restarts, snapshots, many clients (3B) ... ... Passed -- 22.3 5 12478 1412 Test: unreliable net, restarts, partitions, snapshots, many clients (3B) ... ... Passed -- 29.6 5 8653 760 Test: unreliable net, restarts, partitions, snapshots, random keys, many clients (3B) ... ... Passed -- 31.6 7 25416 1802 PASS ok 6.824/kvraft\t151.660s ","date":"2022-02-03T15:06:21+08:00","permalink":"https://cza2000.github.io/2022/mit-6.824-lab3-raftkv/","title":"mit-6.824 lab3: RaftKV"},{"content":"Lab2: Raft lab原链接 https://pdos.csail.mit.edu/6.824/labs/lab-raft.html\nRaft是一种基于复制的状态机协议，通过在多个副本服务器上存储其状态（即数据）的完整副本来实现容错。\nRaft将客户端请求组织成一个称为日志的序列，并通过复制确保所有副本服务器都看到相同的日志。每个副本按日志顺序执行客户端请求，并将它们应用于本地的状态机副本。由于所有副本服务器都看到相同的日志内容，因此它们都以相同的顺序执行相同的请求，从而继续具有相同的服务状态。如果服务器出现故障但随后恢复，Raft保证只要至少半数的服务器存活，并且可以相互通信，就可以保证正常对外服务。\n在本次lab中我们的任务是使用go语言实现raft。参考论文 raft-extended，我们需要实现除了集群成员变更之外的绝大部分内容。论文中我认为最核心的就是描述3个RPC的(Figure 2)这张图，我的实现大体上遵循了这张图。此外我也参考了一些工业级的raft实现，比如SOFAJraft、etcd，做了一些优化。在我秋招面试美团的一个做分布式存储的部门时，他们问了我很多关于raft的内容（虽然最后挂了）。\n有些需要注意的点：\n 当收到的RPC中的term大于自身时，无条件跟随term并转为follower，这在不同的RPC handler中的处理略有不同。 在lab的一些测试用例中，网络将是不稳定的，带来大量随机的RPC丢包、乱序、超时。对于过期的RPC，直接抛弃不处理即可。对于是否过期的判断体现在term太小、身份不正确之类（例如follow收到append entries response）。 锁的使用：在接发RPC、读写channel时一定不要持有锁，不然很有可能死锁。此外有许多代码块对Raft结构中各字段是只读的，我使用了读写锁。  结构体 Raft结构中的各个变量和论文大致一样。\ntype Raft struct { rw sync.RWMutex // Lock to protect shared access to this peer\u0026#39;s state \tpeers []*labrpc.ClientEnd // RPC end points of all peers \tpersister *Persister // Object to hold this peer\u0026#39;s persisted state \tme int // this peer\u0026#39;s index into peers[] \tdead int32 // set by Kill() \t// Your data here (2A, 2B, 2C). \t// Look at the paper\u0026#39;s Figure 2 for a description of what \t// state a Raft server must maintain.  currentState State currentTerm int votedFor int voteFrom map[int]bool logs []LogEntry commitIndex int lastApplied int nextIndex []int matchIndex []int electionTimer *time.Timer heartbeatTimer *time.Timer applyCh chan ApplyMsg applierCond sync.Cond replicatorCond []sync.Cond } func Make(peers []*labrpc.ClientEnd, me int, persister *Persister, applyCh chan ApplyMsg) *Raft { // Your initialization code here (2A, 2B, 2C). \trf := \u0026amp;Raft{ rw: sync.RWMutex{}, peers: peers, persister: persister, me: me, dead: -1, currentState: Follower, currentTerm: 0, votedFor: -1, voteFrom: make(map[int]bool), logs: make([]LogEntry, 1), nextIndex: make([]int, len(peers)), matchIndex: make([]int, len(peers)), electionTimer: time.NewTimer(RandomizedElectionTimeout()), heartbeatTimer: time.NewTimer(StableHeartbeatTimeout()), applyCh: applyCh, replicatorCond: make([]sync.Cond, len(peers)), } rf.applierCond = *sync.NewCond(\u0026amp;rf.rw) rf.logs[0] = LogEntry{0, 0, nil} // initialize from state persisted before a crash \trf.readPersist(persister.ReadRaftState()) rf.commitIndex, rf.lastApplied = rf.logs[0].Index, rf.logs[0].Index for i := 0; i \u0026lt; len(peers); i++ { rf.matchIndex[i], rf.nextIndex[i] = 0, rf.getLastLogEntry().Index+1 if i == me { continue } rf.replicatorCond[i] = *sync.NewCond(\u0026amp;sync.Mutex{}) go rf.replicator(i) } // start ticker goroutine to start elections \tgo rf.ticker() go rf.applier(rf.applyCh) return rf } 根据论文，日志的index和term都从1开始，所以在logs[0]处存放一个index和term均为0的dummy value。\n在Make函数中启动了一些后台协程\n replicator：共len(peers)-1个，用于管理leader对每一个follower的日志复制，下文会详细介绍。 ticker：用来触发选举和心跳timeout。 applier：用于向applyCh中提交已经commit的日志。  leader-election sender 在ticker函数中需要循环使用select监听两个timer的channel，lab的提示中说使用timer可能会有问题但我没有遇到过，懒得改了。\n如果是选举计时器到期，则发起一轮选举；如果是心跳计时器到期，则发起一轮心跳。二者都要首先判断当前身份是否正确。我使用了一个map来记录当前term中投票给自己的peer，需要在每次转换为candidate时清空map。也可以每次start election时声明一个得票计数，之后使用闭包来计算。\nfunc (rf *Raft) ticker() { for !rf.Killed() { select { case \u0026lt;-rf.electionTimer.C: rf.rw.Lock() if rf.currentState != Leader { rf.currentState = Candidate rf.voteFrom = make(map[int]bool) rf.currentTerm++ rf.startElection() } rf.electionTimer.Reset(RandomizedElectionTimeout()) rf.rw.Unlock() case \u0026lt;-rf.heartbeatTimer.C: rf.rw.Lock() if rf.currentState == Leader { DPrintf(\u0026#34;[Server %d] boardcast heartbeat at term %d\u0026#34;, rf.me, rf.currentTerm) rf.boardcastHeartbeat(true) } rf.rw.Unlock() } } } 选举需要异步对每个peer发送request vote，不然就太慢了。异步才不会阻塞ticker，能快速重置计时器。response handler中要先判断是否仍满足rf.currentTerm == args.Term \u0026amp;\u0026amp; rf.currentState == Candidate，若不满足说明RPC过期，直接抛弃不处理。\n我之所以没有使用闭包是因为这样难以抽象出一个 handleRequestVoteResponse 函数，代码结构不够统一。\nfunc (rf *Raft) startElection() { args := rf.getDefaultRequestVoteArgs() rf.votedFor, rf.voteFrom[rf.me] = rf.me, true rf.persist() DPrintf(\u0026#34;[Server %d] start election at term %d\u0026#34;, rf.me, rf.currentTerm) for index := range rf.peers { if index == rf.me { continue } go func(i int) { reply := RequestVoteReply{} if rf.sendRequestVote(i, \u0026amp;args, \u0026amp;reply) { rf.rw.Lock() rf.handleRequestVoteResponse(i, \u0026amp;args, \u0026amp;reply) rf.rw.Unlock() } }(index) } } handler handler的实现完全参照论文，先判断term是否小于自身，再判断term、voteFor和日志是否满足条件。判断voteFor时要先满足args.Term == rf.currentTerm，这是由于args.Term \u0026gt; rf.currentTerm时需要无条件跟随term并重置voteFor。\n需要注意的是只有同意投票时才需要重置election timer，这在课程的TA的guidance中有提及，有利于在网络不稳定时仍能快速选出leader。\nfunc (rf *Raft) RequestVote(args *RequestVoteArgs, reply *RequestVoteReply) { // Your code here (2A, 2B). \tdefer rf.rw.Unlock() defer DPrintf(\u0026#34;[Server %d] reply [%s] for RequestVote to %d\u0026#34;, rf.me, reply, args.CandidateId) rf.rw.Lock() DPrintf(\u0026#34;[Server %d][state %s term %d vote %d lastindex %d lastterm %d] receive RequestVote [%s] from %d\u0026#34;, rf.me, StateName[rf.currentState], rf.currentTerm, rf.votedFor, rf.getLastLogEntry().Index, rf.getLastLogEntry().Term, args, args.CandidateId) if args.Term \u0026lt; rf.currentTerm || (args.Term == rf.currentTerm \u0026amp;\u0026amp; rf.votedFor != -1 \u0026amp;\u0026amp; rf.votedFor != args.CandidateId) { reply.Term, reply.VoteGranted = rf.currentTerm, false return } needToPersist := false if args.Term \u0026gt; rf.currentTerm { rf.currentTerm, rf.votedFor = args.Term, -1 DPrintf(\u0026#34;[Server %d] change state from Leader to Follower at term %d\u0026#34;, rf.me, rf.currentTerm) rf.currentState = Follower needToPersist = true } if !rf.isLogUpToDate(args.LastLogIndex, args.LastLogTerm) { reply.Term, reply.VoteGranted = rf.currentTerm, false if needToPersist { rf.persist() } return } reply.Term, reply.VoteGranted = rf.currentTerm, true rf.votedFor = args.CandidateId rf.persist() rf.electionTimer.Reset(RandomizedElectionTimeout()) } log-replication replicator 根据每个peer的nextIndex判断发送entries或是snapshot。\nresponse handler的实现参照论文，先判断是否过期，再判断是否成功。若成功，则更新match、next index。找到最新的复制到超过半数peer且term等于当前term的日志，更新commit。需要注意日志的term必须和当前term一致才能更新commit，不然可能会有安全性问题导致已经commit的日志被覆盖，我忘了哪个测试一直过不了后来发现就是这个原因，所以论文一定要非常仔细读。\nfunc (rf *Raft) doReplicate(i int) { rf.rw.RLock() if rf.currentState != Leader { rf.rw.RUnlock() return } if rf.nextIndex[i] \u0026lt;= rf.getDummyLogntry().Index { args := rf.getDefaultInstallSnapshotArgs() rf.rw.RUnlock() reply := InstallSnapshotReply{} if rf.sendInstallSnapshot(i, \u0026amp;args, \u0026amp;reply) { rf.rw.Lock() rf.handleInstallSnapshotResponse(i, args, reply) rf.rw.Unlock() } } else { args := rf.getDefaultAppendEntriesArgs(i) rf.rw.RUnlock() reply := AppendEntriesReply{} if rf.sendAppendEntries(i, \u0026amp;args, \u0026amp;reply) { rf.rw.Lock() rf.handleAppendEntriesReponse(i, \u0026amp;args, \u0026amp;reply) rf.rw.Unlock() } } } 这里我参考了 LebronAI 的设计。\n如果为每一次Start、心跳都广播发送一次append entries，则将下层的日志同步与上层的提交新指令强绑定了，会造成RPC数量过多，还会重复发送很多次相同的日志项。每次发送 rpc 都不论是发送端还是接收端都需要若干次系统调用和内存拷贝，rpc 次数过多也会对 CPU 造成不必要的压力。\n这里可以做一个batching的优化，也将二者之间解耦。这里原作者参考了SOFAJraft的日志复制模型，让每个peer对于其他所有peer各维护一个replicator协程，负责在自己成为leader时对单独一个peer的日志复制。\n这个协程利用条件变量 sync.Cond 执行 Wait 来避免耗费 cpu，每次需要进行一次日志复制时调用 Signal 唤醒。它在满足复制条件时会尽最大努力将[nextIndex, lastIndex]之间的日志复制到peer上。\n由于leader使用replicator维护对于一个peer的日志复制，同一时间下最多只会发送一个RPC，若RPC丢失、超时很可能触发re-election。因此：\n 心跳计时器到期，很急，要立即发送RPC。leader commit更新时也要立即发送RPC，这个是为啥我忘记了。 Start被调用，不急，只需调用条件变量的 Singal，让replicator慢慢发。  func (rf *Raft) replicator(peer int) { rf.replicatorCond[peer].L.Lock() defer rf.replicatorCond[peer].L.Unlock() for !rf.Killed() { for !rf.needToReplicate(peer) { rf.replicatorCond[peer].Wait() } rf.doReplicate(peer) } } func (rf *Raft) needToReplicate(peer int) bool { rf.rw.RLock() defer rf.rw.RUnlock() return rf.currentState == Leader \u0026amp;\u0026amp; rf.nextIndex[peer] \u0026lt;= rf.getLastLogEntry().Index } func (rf *Raft) boardcastHeartbeat(isHeartbeat bool) { for index := range rf.peers { if index == rf.me { continue } if isHeartbeat { go rf.doReplicate(index) } else { rf.replicatorCond[index].Signal() } } rf.heartbeatTimer.Reset(StableHeartbeatTimeout()) } handler 完全按照论文图中伪代码实现，包括了课程视频中提到的加速解决日志冲突的优化。\nfunc (rf *Raft) AppendEntries(args *AppendEntriesArgs, reply *AppendEntriesReply) { rf.rw.Lock() DPrintf(\u0026#34;[Server %d][term %d lastindex %d lastterm %d commit %d] receive AppendEntries %+v from %d\u0026#34;, rf.me, rf.currentTerm, rf.getLastLogEntry().Index, rf.getLastLogEntry().Term, rf.commitIndex, args, args.LeaderId) defer rf.rw.Unlock() defer DPrintf(\u0026#34;[Server %d] reply [%s] for AppendEntries to %d\u0026#34;, rf.me, reply, args.LeaderId) needToPersist := false if args.Term \u0026lt; rf.currentTerm { reply.Success, reply.Term = false, rf.currentTerm return } if args.Term \u0026gt; rf.currentTerm { rf.currentTerm = args.Term needToPersist = true } rf.currentState = Follower rf.electionTimer.Reset(RandomizedElectionTimeout()) if args.PrevLogIndex \u0026lt; rf.getDummyLogntry().Index { reply.Success, reply.Term = false, 0 if needToPersist { rf.persist() } return } if !rf.isLogMatch(args.PrevLogIndex, args.PrevLogTerm) { reply.Term, reply.Success = rf.currentTerm, false reply.XIndex, reply.Term = rf.getConflictEntry(args.PrevLogIndex) if needToPersist { rf.persist() } return } lastLogIndex := rf.getLastLogEntry().Index for index, entry := range args.Entries { if entry.Index \u0026gt; lastLogIndex || rf.logs[rf.getSliceIndex(entry.Index)].Term != entry.Term { rf.logs = append(rf.logs[:rf.getSliceIndex(entry.Index)], args.Entries[index:]...) DPrintf(\u0026#34;[Server %d] append Follower\u0026#39;s last log index from %d to %d\u0026#34;, rf.me, lastLogIndex, rf.getLastLogEntry().Index) needToPersist = true break } } rf.maybeAdvanceFollowerCommit(args.LeaderCommit) reply.Success = true if needToPersist { rf.persist() } } persistence 论文中提到有三个变量是需要持久化的：currentTerm、votedFor、log[]，这三个量每次改变之后都应该持久化。\n持久化应当在被其他协程感知（发送RPC、释放锁）之前完成，而每个函数中如果没有改变这三个量（如加锁之后发现RPC过期）则不用持久化，若有也只需持久化一次，所以我在很多地方都使用了一个 needToPersist 布尔量进行判断。这样写感觉不够优雅，暂时没想到其他方法。\nlog-compaction 对于leader，在replicator中根据next index判断出需要给peer发送快照时，调用 persister.ReadSnapshot 获得快照并发送。\n对于接收方，需要判断如果 args.LastIncludedIndex \u0026lt;= rf.commitIndex，则拒绝接收快照。这说明本地状态机已经至少比该快照更新（或者将要，因为applier协程已经在apply这些日志的过程中了），可能导致raft回到旧的状态。应当等待service层调用 Snapshot 函数来安装快照。接收快照后，异步写入到applyCh中。\n对于两个service层给raft层安装快照的函数，它们的区别是：Snapshot 是由service层在处理apply message时判断raft state\u0026rsquo;s size是否达到阈值，主动调用。CondInstallSnapshot 是service层在处理apply message中leader发来的更新的快照时调用，也需要再次判断是否 LastIncludedIndex \u0026lt;= rf.commitIndex，安装快照之后应该更新lastApplied、commitIndex。\n安装快照后需要压缩日志，但是需要记录下包含在快照中的最新的日志项的index和term，我将其记录在dummy entry（即rf.log[0]）中。此外被删除的日志项需要被正确的删除使其能够被gc。\napplier 根据论文，一旦commitIndex \u0026gt; lastApplied，则需要将[lastApplied+1, commitIndex]中的所有日志项apply到状态机并增加lastApplied。\n一开始我的实现是每次commitIndex更新，都异步起一个协程将[lastApplied+1, commitIndex]间日志写入applyCh。但是因为写channel时不能持有锁，所以这个过程只能是：\n加锁 -\u0026gt; 深拷贝日志项 -\u0026gt; 释放锁 -\u0026gt; 写channel -\u0026gt; 加锁 -\u0026gt; 更新lastApplied -\u0026gt; 释放锁\n日志在push完之前不会更新lastApplied，这样容易造成相同的日志项被重复apply，存在资源浪费。所以这里也可以参考之前replicator的实现思路，后台起一个applier协程，平时调用一个条件变量的 Wait ，被 Signal 唤醒时将[lastApplied+1, commitIndex]中的所有日志项apply到状态机，每次更新commitIndex时调用 Signal。这样即能避免日志被重复apply，也完成了 apply 日志到状态机和 raft 提交新日志之间的解耦。\nfunc (rf *Raft) applier(applyCh chan ApplyMsg) { for !rf.Killed() { rf.rw.Lock() for !rf.needToApply() { rf.applierCond.Wait() } lastApplied, commitIndex := rf.lastApplied, rf.commitIndex needToApply := DeepCopy(rf.logs[rf.getSliceIndex(lastApplied+1) : rf.getSliceIndex(commitIndex)+1]) rf.rw.Unlock() for _, entry := range needToApply { applyMsg := ApplyMsg{ CommandValid: true, Command: entry.Command, CommandIndex: entry.Index, CommandTerm: entry.Term, RaftStateSize: rf.persister.RaftStateSize(), } applyCh \u0026lt;- applyMsg DPrintf(\u0026#34;[Server %d] applied log [index %d] at term %d\u0026#34;, rf.me, entry.Index, entry.Term) } rf.rw.Lock() if commitIndex \u0026gt; rf.lastApplied { rf.lastApplied = commitIndex } rf.rw.Unlock() } } 需要注意因为写channel时是不加锁的，而写channel是可能出现并发的，可能存在一种情况：applier在写入一批旧日志时，follower接受leader的 InstallSnapshot 之后将新的snapshot写入channel。此时channel的写入顺序可能是：旧日志1 -\u0026gt; 新快照 -\u0026gt; 旧日志2。\nservice层读channel是线性的，在读出snapshot并调用 CondInstallSnapshot 后会更新raft层的lastApplied、commitIndex。因此在raft层apply完日志之后，重新获得锁去更新lastApplied时要注意不能回退，在这二者之间可能service层已经对更新的快照调用过 CondInstallSnapshot 了（新快照的 lastIncludeIndex 一定大于 commitIndex ）。\n测试结果 2A Test (2A): initial election ... ... Passed -- 3.6 3 46 12142 0 Test (2A): election after network failure ... ... Passed -- 5.6 3 94 19292 0 Test (2A): multiple elections ... ... Passed -- 7.9 7 534 113432 0 PASS ok 6.824/raft\t17.177s 2B Test (2B): basic agreement ... ... Passed -- 1.1 3 16 4326 3 Test (2B): RPC byte count ... ... Passed -- 1.3 3 48 153910 11 Test (2B): agreement despite follower disconnection ... ... Passed -- 4.3 3 75 19840 7 Test (2B): no agreement if too many followers disconnect ... ... Passed -- 4.7 5 146 33983 4 Test (2B): concurrent Start()s ... ... Passed -- 1.5 3 18 5054 6 Test (2B): rejoin of partitioned leader ... ... Passed -- 5.1 3 117 27458 4 Test (2B): leader backs up quickly over incorrect follower logs ... ... Passed -- 9.8 5 1023 627193 102 Test (2B): RPC counts aren't too high ... ... Passed -- 3.0 3 42 12296 12 PASS ok 6.824/raft\t30.976s 2C Test (2C): basic persistence ... ... Passed -- 6.0 3 91 21819 6 Test (2C): more persistence ... ... Passed -- 18.3 5 821 178397 16 Test (2C): partitioned leader and one follower crash, leader restarts ... ... Passed -- 2.7 3 35 8235 4 Test (2C): Figure 8 ... ... Passed -- 27.9 5 530 117688 23 Test (2C): unreliable agreement ... ... Passed -- 3.0 5 753 240518 246 Test (2C): Figure 8 (unreliable) ... ... Passed -- 36.6 5 1684 3862021 145 Test (2C): churn ... ... Passed -- 16.5 5 7937 3098958 1199 Test (2C): unreliable churn ... ... Passed -- 16.3 5 1631 1031494 298 PASS ok 6.824/raft\t127.309s 2D Test (2D): snapshots basic ... ... Passed -- 2.4 3 247 96514 251 Test (2D): install snapshots (disconnect) ... ... Passed -- 46.7 3 1035 293753 399 Test (2D): install snapshots (disconnect+unreliable) ... ... Passed -- 52.4 3 1153 310385 377 Test (2D): install snapshots (crash) ... ... Passed -- 32.0 3 722 206681 322 Test (2D): install snapshots (unreliable+crash) ... ... Passed -- 43.7 3 806 220815 388 PASS ok 6.824/raft\t177.243s ","date":"2022-02-03T15:04:30+08:00","permalink":"https://cza2000.github.io/2022/mit-6.824-lab2-raft/","title":"mit-6.824 lab2: Raft"},{"content":"Lab1: MapReduce 在本次lab中我们的任务是实现一个分布式的MapReduce，它由两个程序组成，Coordinator和Worker。只有一个Coordinator，一个或多个Worker并行执行。\n每个Worker将通过RPC与Coordinator通信以请求一个Map或Reduce任务，之后从一个或多个文件中读取任务的输入，执行任务，并将任务的输出写入一个或多个文件。\nCoordinator应注意到Worker是否在合理的时间内（10s）完成了任务，如果没有则将相同的任务交给另一个Worker。\nCoordinator 写这个lab的时候刚学go语言不久，觉得channel这个东西很帅，就使用了很多channel实现了一个lock-free版本的Coordinator，实践了一下csp。\n核心结构体 Coordinator维护每一个Map和Reduce任务的状态，这样就不用维护每一个worker的状态，这也利于worker的弹性伸缩。\nxxxidCh用于在获取任务编号并发放给worker，xxxDoneCh和xxxUndoneCh用于获取完成或未完成的任务编号修改任务状态。\ntype Coordinator struct { files []string nMap int nReduce int mapidCh chan int reduceidCh chan int mapStatus []Task reduceStatus []Task heartbeatCh chan heartbeatMsg reportCh chan reportMsg stateCh chan getStateMsg mapDoneCh chan Execution reduceDoneCh chan Execution mapUndoneCh chan Execution reduceUndoneCh chan Execution mapComplete bool reduceComplete bool mapRemain int reduceRemain int } 每个任务的状态有3种，每个任务被初始化时都是UnStarted，被分配给Worker之后转换为Processing，收到Report完成转为Done，未完成转为UnStarted。\n结构体Task用term和任务状态共同表示一个任务的信息，term代表该任务被分配给worker执行的次数。\ntype TaskStatus int const ( UnStarted TaskStatus = iota Processing Done ) type Task struct { term int TaskStatus } RPC-handler Coordinator接收到RPC之后，包装出一个xxxMsg结构，传入RPC对应的channel中。\nDone在这里作用类似于一个回调。Coordinator在启动时会在后台启动一个goroutine，不断监控 heartbeatCh 和 reportCh 中的Msg并处理，处理完成后执行msg.Done \u0026lt;- struct{}{}。在RPC handler中只需要等待Done这个channel返回。\ntype heartbeatMsg struct { response *HeartbeatResponse Done chan struct{} } type reportMsg struct { request *ReportRequest Done chan struct{} } func (c *Coordinator) Heartbeat(request *HeartbeatRequest, response *HeartbeatResponse) error { log.Println(\u0026#34;[Coordinator] receive a request from worker\u0026#34;) msg := heartbeatMsg{ response: response, Done: make(chan struct{}), } c.heartbeatCh \u0026lt;- msg \u0026lt;-msg.Done log.Printf(\u0026#34;[Coordinator] run heartbeat [%s] for worker\u0026#34;, response) return nil } func (c *Coordinator) Report(request *ReportRequest, response *ReportResponse) error { log.Printf(\u0026#34;[Coordinator] receive worker\u0026#39;s report [%s]\u0026#34;, request) msg := reportMsg{ request: request, Done: make(chan struct{}), } c.reportCh \u0026lt;- msg \u0026lt;-msg.Done log.Println(\u0026#34;[Coordinator] finish dealing with the report from worker\u0026#34;) return nil } handleHeartbeatMsg函数中处理心跳，根据当前Map和Reduce任务的状态给Worker分配一个任务、让worker等待或是告知所有任务已经完成。任务的id从mapidCh或reduceidCh两个channel中读出，在response中还要加上任务的term，每次分配该任务前需要对term自增以在不同的执行者之间区分。\n那么任务的id是什么时候写入channel中的呢？Coordinator在初始化时先将所有Map任务的id写入mapidCh，在所有Map任务都完成后将所有Reduce任务的id写入reduceidCh。\n需要注意一点，每个任务在分配之后10s内如果没有收到Report，则应该默认任务失败。这需要另起一个goroutine来判断，直接sleep 10s之后将id写入Undone channel即可，让run函数去判断。\n在handleReportMsg函数中处理worker的返回任务结果，根据结构类型将任务的Execution写入对应的Done/Undone channel。我将任务的term和id包装成一个Execution结构表示任务的一次执行，使得某次任务失败是超时还是worker返回失败这两种情况可以被区分。\ntype Execution struct { term int id int } 核心逻辑 run函数是Coordinator的核心，它作为一个后台运行的goroutine在不断的循环中监听各个channel并执行对应的操作。由于所有的数据都在这一个goroutine中修改，避免了data-race。\nCoordinator真正处理worker上报的任务的完成情况是由run函数在select中同时监听这4个channel，再根据任务id来执行对应逻辑。因此handleReportMsg函数可以另起一个goroutine来执行，这4个channel的容量也只需设置为1。\n从4个channel读出任务id后要注意，只有在对应的状态、Execution中term和本地任务的term一致时才能执行逻辑。\n例如某个MapFailed消息在10s之后到达，这可能是因为网络拥塞或是worker执行任务太慢，这个map任务已经被重新分配给了另一个worker，此时状态是仍是Processing。但这时term不一致应该放弃处理这个MapFailed消息。\nfunc (c *Coordinator) run() error { for { select { case hbMsg := \u0026lt;-c.heartbeatCh: c.handleHeartbeatMsg(hbMsg) case rpMsg := \u0026lt;-c.reportCh: go c.handleReportMsg(rpMsg) case e := \u0026lt;-c.mapDoneCh: if c.mapStatus[e.id].TaskStatus == Processing \u0026amp;\u0026amp; c.mapStatus[e.id].term == e.term { ··· } case e := \u0026lt;-c.reduceDoneCh: if c.reduceStatus[e.id].TaskStatus == Processing \u0026amp;\u0026amp; c.reduceStatus[e.id].term == e.term { ··· } case e := \u0026lt;-c.mapUndoneCh: if c.mapStatus[e.id].TaskStatus == Processing \u0026amp;\u0026amp; c.mapStatus[e.id].term == e.term { ··· } case e := \u0026lt;-c.reduceUndoneCh: if c.reduceStatus[e.id].TaskStatus == Processing \u0026amp;\u0026amp; c.reduceStatus[e.id].term == e.term { ··· } case stMsg := \u0026lt;-c.stateCh: stMsg.state \u0026lt;- c.reduceComplete } } } Worker worker的实现比较简单，只需要循环向coordinator请求任务执行。\nfunc Worker(mapf func(string, string) []KeyValue, reducef func(string, []string) string) { // Your worker implementation here. \tfor { response := doHeartbeat() log.Printf(\u0026#34;[Worker] receive coordinator\u0026#39;s heartbeat [%s]\u0026#34;, response) switch response.Type { case Map: doMapTask(mapf, response.Id, response.Term, response.NReduce, response.Name) case Reduce: doReduceTask(reducef, response.Id,response.Term, response.NMap) case Wait: time.Sleep(1 * time.Second) case Completed: return default: panic(fmt.Sprintf(\u0026#34;[Worker] unexpected jobType %v\u0026#34;, response.Type)) } } } 执行Map任务时，只需将mapf函数产生的中间文件kv pair按照ihash(kv.Key)%nReduce的余数写入不同的文件等待Reduce即可。写入的文件要先调用ioutil.TempFile(\u0026quot;\u0026quot;, \u0026ldquo;temp\u0026rdquo;)生成再调用os.Rename()改为mr-i-j。\n执行Reduce任务时，先建立一个kv数组，再将所有中间文件中的kv pair append到数组中再排序，将相同key对应的所有value append到一个string数组中，喂给reducef函数执行。看起来非常暴力，在工业界应该不可行，但通过本次lab的测试足够了。\n","date":"2022-02-03T15:01:24+08:00","permalink":"https://cza2000.github.io/2022/mit-6.824-lab1-mapreduce/","title":"mit-6.824 lab1: MapReduce"},{"content":"前言 21年的3月份，大三下学期，我收到了一份暑期实习的offer。需要提前学习一下go语言，之后在某学长的安利下我了解到了mit-6.824这门课程，他建议我做一下这门课的4个lab就当实践一下go。不过我配好环境后就去浪了2333，也就断断续续的在b站上看了几期课的视频。\n真正开始写lab还是暑假实习在公司摸鱼的时候开始的，当时还拉着旁边组的一个实习生一起写相互交流进度。不得不说，课程、论文和lab真的都是非常非常的硬核（虽然我论文只大概看了前几篇），分布式系统这个领域也真的是非常非常的有趣，比学校里学的东西不知道高到哪里去了。暑假结束时还只写完了lab2，lab3只写了一点点，之后由于搞完秋招后一直在玩，年底又去写PingCAP talent-plan的tinykv了（这个也挺有意思的，也更贴近工业界，可惜文档给的太少，与之相比6.824的实现就像个玩具）导致进度很慢，最终22年1月中旬才全部写完。\n最近（毕业之前）我应该会将整理完所有的文档、实现思路发出来，也锻炼一下自己写技术文章的水平。\n一些资料 我的实验配置  win10 + wsl2 + ubuntu 20.04 16G内存 go version 1.15  课程网站 6.824 Schedule: Spring 2021\n用于并发测试的脚本 #!/bin/bash rm -rf tmp-$1 mkdir tmp-$1 start_time=$(date + %s) [ -e /tmp/fd1 ] || mkfifo /tmp/fd1 exec 3\u0026lt;\u0026gt;/tmp/fd1 rm -rf /tmp/fd1 # 同时执行 10 个线程，依照cpu核心数视情况而定 for ((i = 1; i \u0026lt;= 10; i++)); do echo \u0026gt;\u0026amp;3 done for ((i = 1; i \u0026lt;= 500; i++)); do read -u3 { touch ./tmp-$1/report_$i.log go test -run $1 -race \u0026gt; ./tmp-$1/report_$i.log s=$(tail -n 1 ./tmp-$1/report_$i.log) if [ ${s:0:2} == \u0026#39;ok\u0026#39; ] then rm ./tmp-$1/report_$i.log else echo \u0026#34;test $iFailed\u0026#34; fi echo \u0026gt;\u0026amp;3 } \u0026amp; done wait stop_time=$(date +%s) echo \u0026#34;TIME:$(expr $stop_time - $start_time)\u0026#34; exec 3\u0026lt;\u0026amp;- exec 3\u0026gt;\u0026amp;- ","date":"2022-02-03T14:01:24+08:00","permalink":"https://cza2000.github.io/2022/mit-6.824-lab0-preface/","title":"mit-6.824 lab0: Preface"},{"content":"开端 一个程序员怎么能没有一个属于自己的技术博客呢？念叨这句话很久了，22年的春节我终于新建了文件夹。\n技术栈选型 框架 Hugo ，主题 Stack ，托管于 GitHub Pages，域名备案于阿里云。此外使用了 Github Actions 进行自动化部署。\n框架 一开始只知道博客可以托管在GitHub Pages上，作为完全不懂前端的我，肯定要选个简单的博客框架，上网查了下主要有Hexo和Hugo。\n Hexo？要用 nodejs，先pass。 Hugo？是 go 语言开发的，这我熟，就它了！  Hugo 是由 Go 语言实现的静态网站生成器。简单、易用、高效、易扩展、快速部署。Hugo 的速度真的非常快，本地运行后，更新一保存之后马上在浏览器之后就能看到结果。此外还要选个主题，我用的是 Stack。具体看 Hugo 官方文档 和 Stack 官方文档。\n折腾博客的各种小细节时，基本都在参考这位博主的 装修记录。\n需要注意一点，Hugo 框架的文件结构和 themes 中主题的文件结构是相同的，在修改样式时需要将主题文件夹中的同名文件复制到外边再做修改。若在主题文件夹中修改，由于自动化部署时是在 GitHub Actions 提供的 runner 上每次重新获取 hugo 和 theme 来生成静态网站，本地的更改就没了。\n写博客时，只需先执行\nhugo new post/xxx.md 之后修改顶部的 FrontMatter\n--- title: \u0026#34;my title\u0026#34; description: \u0026#34;my description\u0026#34; date: 2022-02-03T15:01:24+08:00 draft: true tags: - tag1 categories: - categorie1 --- 再之后就可以开始创作了。\n后端 将博客托管在Github Pages上，具体看 官网。\n新建一个public Repository，名字要是 username.github.io。之后在hugo框架根目录下执行 hugo -D 在 public 文件夹中生成静态网站，再将 public 文件夹中内容 push 到该 Repository 中即可完成部署。\n自动化部署 每次部署很麻烦，需要以下步骤：\nhugo -D cd public git add . git commit -m \u0026#34;some messages\u0026#34; git push 而且这样想要用git管理源文件有一点麻烦，自然想到使用 GitHub Actions 来完成自动化部署。\n需要先新建一个 Repository 保存博客框架源文件，我取名为 my-hugo-stack。username.github.io 这个Repository保存的是静态网站文件，不要混淆。\n在 my-hugo-stack 的 Actions 中，新建一个 workflow ，点击 configure 写入以下内容\nname: ci on: push: branches: - master jobs: build: runs-on: ubuntu-latest steps: - name: checkout uses: actions/checkout@v2.3.4 with: submodules: true - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: \u0026#39;0.92.1\u0026#39; extended: true - name: Build run: hugo -D - name: Add CNAME run: echo \u0026#34;ziannchen.work\u0026#34; \u0026gt; public/CNAME - name: Deploy uses: peaceiris/actions-gh-pages@v3 with: deploy_key: ${{ secrets.ACTIONS_DEPLOY_KEY }} external_repository: cza2000/cza2000.github.io publish_branch: master publish_dir: ./public commit_message: ${{ github.event.head_commit.message }} 此外还需要新建一对SSH密钥。私钥写入博客源文件仓库的 Settings - Actions secrets，命名为 ACTIONS_DEPLOY_KEY，公钥写入静态网站仓库的 Settings - Deploy keys，命名随意。\n之后将本地博客源文件 push 至 my-hugo-stack 的 master 分支就会触发 action，自动部署并将生成的 public 文件夹内的内容 push 到 username.github.io 中完成部署。\n由于我买了域名，这样做每次都把我的 CNAME 搞没了，我就在 yml 文件中手动加了一个 step，每次重新生成 CNAME 文件。\n为了更懒一点，又写了个脚本 deploy.sh:\n#!/bin/sh git add . msg=\u0026#34;rebuilding site $(date)\u0026#34; if [ -n \u0026#34;$*\u0026#34; ]; then msg=\u0026#34;$*\u0026#34; fi git commit -m \u0026#34;$msg\u0026#34; # Push source and build repos. git push TODO  考虑弄个 CDN  ","date":"2022-01-31T14:38:17+08:00","permalink":"https://cza2000.github.io/2022/hugostack-github-pages-github-actions-%E5%BB%BA%E7%AB%99%E8%AE%B0%E5%BD%95/","title":"Hugo\u0026Stack + Github Pages + Github Actions 建站记录"}]